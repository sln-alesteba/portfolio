<!DOCTYPE html>

<html>
    
    <head>
      
        <meta charset=utf-8>

        <!-- check the post for the entire code https://waloncab.github.io/s.ln_blog/posts/jekyll-build-config.html -->

        <title>sln-alesteba:blog </title>
          
        <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="sln-alesteba:blog" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!" />
<meta property="og:description" content="Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!" />
<link rel="canonical" href="https://sln-alesteba.github.io/portfolio/portfolio/search.html" />
<meta property="og:url" content="https://sln-alesteba.github.io/portfolio/portfolio/search.html" />
<meta property="og:site_name" content="sln-alesteba:blog" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="sln-alesteba:blog" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!","headline":"sln-alesteba:blog","url":"https://sln-alesteba.github.io/portfolio/portfolio/search.html"}</script>
<!-- End Jekyll SEO tag -->


        <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/body.css">
        <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/table.css">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-GP7FZ2055V"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-GP7FZ2055V');
        </script>

        <!-- FAVICONS -->

        <link rel="apple-touch-icon" sizes="180x180" href="https://sln-alesteba.github.io/portfolio/assets/fav/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://sln-alesteba.github.io/portfolio/assets/fav/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://sln-alesteba.github.io/portfolio/assets/fav/favicon-16x16.png">
        <link rel="manifest" href="https://sln-alesteba.github.io/portfolio/assets/fav/site.webmanifest">
        <link rel="mask-icon" href="https://sln-alesteba.github.io/portfolio/assets/fav/safari-pinned-tab.svg" color="#5bbad5">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">

    </head>

    <body>

        <div class="content">

            <div class="header">
         
    <h1>sln-alesteba:blog</h1>

    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/social.css">
    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/header.css">

    <meta name="viewport" content="width=device-width, initial-scale=1"> 
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.6.js"></script> 


    <script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>

    <script type="importmap">
    {
        "imports": {
        "three": "https://unpkg.com/three/build/three.module.js"
        }
    }
    </script>

    <p>
        <a href="https://www.youtube.com/channel/UCJX8AUDFcQJMjY1zRivvZqw" class="fa fa-youtube"></a>
        <a href="https://www.instagram.com/sln-alesteba/" class="fa fa-instagram"></a>
        <a href="https://www.instagram.com/walon_cab/" class="fa fa-facebook"></a>
        <a href="https://twitter.com/WalonCab" class="fa fa-twitter"></a>
    </p>

</div> 

            <br>
            
            <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/nav.css">

<!-- https://www.w3schools.com/howto/howto_js_topnav_responsive.asp -->

<div class="topnav" id="myTopnav">

    <!-- <a href="https://sln-alesteba.github.io/portfolio/index.html" class="active">Blog</a>
    <a href="https://sln-alesteba.github.io/portfolio/about">About</a>
    <a href="https://sln-alesteba.github.io/portfolio/demos">Demos</a> -->

    <!-- <ul> -->

        
        
        <a href="https://sln-alesteba.github.io/portfolio/about/">About</a><a href="https://sln-alesteba.github.io/portfolio/blog/">Blog</a><a href="https://sln-alesteba.github.io/portfolio/demos/">Demos</a><a href="https://sln-alesteba.github.io/portfolio/projects/">Projects</a>

    <!-- </ul> -->

    <div class="search-container">

        
        <!-- <form action="/action_page.php">
          <input type="text" placeholder="Search.." name="search">
          <button type="submit">Submit</button>
        </form> -->

        <form action='https://sln-alesteba.github.io/portfolio/search.html' method="get">
            <input type="text" id="search-box" name="query">
            <!-- <input type="submit" value="search"> -->
            <button type="submit" value="search">Submit</button>
        </form>
    </div>

    <a href="javascript:void(0);" class="icon" onclick="myFunction()">
      <i class="fa fa-bars"></i>
    </a>

</div>

<script>
    /* Toggle between adding and removing the "responsive" class to topnav when the user clicks on the icon */
    function myFunction() {
        var x = document.getElementById("myTopnav");
        if (x.className === "topnav") {
            x.className += " responsive";
        } else {
            x.className = "topnav";
        }
    }
</script>

            <br>

            <script src="https://unpkg.com/lunr/lunr.js"></script>

<!-- <form action="/search.html" method="get">
  <label for="search-box">Search</label>
  <input type="text" id="search-box" name="query">
  <input type="submit" value="search">
</form> -->

<ul id="search-results"></ul>

<script>
  window.store = {

    
      "posts-nerf-ficus-html": {
        "title": "NeRF - A concrete example, Ficus",
        "author": "alesteba",
        "category": "",
        "content": " explicación inicial, hace falta algo de texto ",
        "url": "/posts/NeRF_ficus.html"
      }
      ,
    
      "posts-lof-outlier-pipeline-html": {
        "title": "LOF Outlier Imblearn Pipeline",
        "author": "alesteba",
        "category": "",
        "content": "2023-03-11-LOF-outlier-pipeline                    In this post we examine how to append a local outlier factor method to a regular pipeline, but using imblearn ones.Lets review how to use pipelines when the shape of the dataset need to be modified, such as with outlier removal.In&nbsp;[17]:     import pandas as pdimport numpy as np     In&nbsp;[18]:     # import a basic dataset.df = pd.read_csv(&#39;data/housing.csv&#39;, na_values=&#39;?&#39;)df.head()             Out[18]:                  0.00632      18.00      2.310      0      0.5380      6.5750      65.20      4.0900      1      296.0      15.30      396.90      4.98      24.00                  0      0.02731      0.0      7.07      0      0.469      6.421      78.9      4.9671      2      242.0      17.8      396.90      9.14      21.6              1      0.02729      0.0      7.07      0      0.469      7.185      61.1      4.9671      2      242.0      17.8      392.83      4.03      34.7              2      0.03237      0.0      2.18      0      0.458      6.998      45.8      6.0622      3      222.0      18.7      394.63      2.94      33.4              3      0.06905      0.0      2.18      0      0.458      7.147      54.2      6.0622      3      222.0      18.7      396.90      5.33      36.2              4      0.02985      0.0      2.18      0      0.458      6.430      58.7      6.0622      3      222.0      18.7      394.12      5.21      28.7      In&nbsp;[19]:     # define target variable     In&nbsp;[20]:     # https://www.kaggle.com/code/jonaspalucibarbosa/removing-outliers-within-a-pipeline# interquartile mehtod for outlier detectiondef customsampler_IQR (X, y):        features = X.columns    df = X.copy()    df[&#39;Outcome&#39;] = y        indices = [x for x in df.index]        out_indexlist = []            for col in features:               Q1 = np.nanpercentile(df[col], 25.)        Q3 = np.nanpercentile(df[col], 75.)                cut_off = (Q3 - Q1) * 1.5        upper, lower = Q3 + cut_off, Q1 - cut_off                        outliers_index = df[col][(df[col] &lt; lower) | (df[col] &gt; upper)].index.tolist()        outliers = df[col][(df[col] &lt; lower) | (df[col] &gt; upper)].values                out_indexlist.extend(outliers_index)            out_indexlist = list(set(out_indexlist))        clean_data = np.setdiff1d(indices,out_indexlist)    return X.loc[clean_data], y.loc[clean_data]     In&nbsp;[21]:     last_ix = len(df.columns) - 1X = df.drop(df.columns[last_ix], axis=1)y = df[df.columns[last_ix]]print(X.shape, y.shape)             (505, 13) (505,)Now we can use an imblearn pipeline (since the shape of the y can be changed) and apply the transformation to the original dataset.The usage of the previous defined function is straightforward, create a new step and embed it into a FunctionSampler.In&nbsp;[22]:     # use of imblearn pipelinesfrom sklearn.model_selection import train_test_splitfrom imblearn.pipeline import Pipelinefrom imblearn import FunctionSampler# define the pipelineclf = Pipeline(    steps=[        (&#39;o&#39;, FunctionSampler(func=customsampler_IQR, validate = False))    ])clf.fit(X, y)X_enc, y_enc = clf.fit_resample(X, y)X_enc.shape             Out[22]:(274, 13)In&nbsp;[23]:     X_enc             Out[23]:                  0.00632      18.00      2.310      0      0.5380      6.5750      65.20      4.0900      1      296.0      15.30      396.90      4.98                  0      0.02731      0.0      7.07      0      0.469      6.421      78.9      4.9671      2      242.0      17.8      396.90      9.14              1      0.02729      0.0      7.07      0      0.469      7.185      61.1      4.9671      2      242.0      17.8      392.83      4.03              2      0.03237      0.0      2.18      0      0.458      6.998      45.8      6.0622      3      222.0      18.7      394.63      2.94              3      0.06905      0.0      2.18      0      0.458      7.147      54.2      6.0622      3      222.0      18.7      396.90      5.33              4      0.02985      0.0      2.18      0      0.458      6.430      58.7      6.0622      3      222.0      18.7      394.12      5.21              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              500      0.06263      0.0      11.93      0      0.573      6.593      69.1      2.4786      1      273.0      21.0      391.99      9.67              501      0.04527      0.0      11.93      0      0.573      6.120      76.7      2.2875      1      273.0      21.0      396.90      9.08              502      0.06076      0.0      11.93      0      0.573      6.976      91.0      2.1675      1      273.0      21.0      396.90      5.64              503      0.10959      0.0      11.93      0      0.573      6.794      89.3      2.3889      1      273.0      21.0      393.45      6.48              504      0.04741      0.0      11.93      0      0.573      6.030      80.8      2.5050      1      273.0      21.0      396.90      7.88      274 rows × 13 columnsAnd finally, we use it with a machine learning model. The process is completly reusable, just add another step to the pipeline after the IQR method.The following cell uses imputaton strategies, data scalation and a simple LinearDiscriminantAnalysis at the end of the preprocess transformations.In&nbsp;[24]:     from imblearn import FunctionSamplerfrom imblearn.pipeline import pipeline     In&nbsp;[25]:     from sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.impute import SimpleImputerfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_scorefrom sklearn.preprocessing import MinMaxScaler     In&nbsp;[&nbsp;]:     model = LinearDiscriminantAnalysis()strategies = [&#39;mean&#39;, &#39;median&#39;, &#39;most_frequent&#39;, &#39;constant&#39;]  trans = MinMaxScaler()results = []for s in strategies:    # create the modeling pipeline    pipe = Pipeline(        steps=[            (&#39;o&#39;, FunctionSampler(func=customsampler_IQR, validate = False)),            (&#39;i&#39;, SimpleImputer(strategy=s)),            (&#39;t&#39;, trans),               (&#39;m&#39;, model),        ])        # evaluate the model    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1)    scores = cross_val_score(pipe, X, y, scoring=&#39;accuracy&#39;, cv=cv, n_jobs=-1,error_score=&quot;raise&quot;)  #array    # store results    results.append(scores)        # print    print(&#39;&gt;%s %.3f (%.3f)&#39; % (s, np.mean(scores), np.std(scores)))     ",
        "url": "/posts/LOF-outlier-pipeline.html"
      }
      ,
    
      "posts-polinomial-iterpolation-html": {
        "title": "Polynomial Interpolation",
        "author": "alesteba",
        "category": "",
        "content": "2023-03-04-polinomial-iterpolation                    Since many of the things that we do in the blog are about splines, in this post we're going to cover how to fit polynomials and splines to random scatter points.We'll use some of the basic scikit-learn functionality to avoid implementing the polynomial transformations from scratch. In this case a 2d aproach is more than enough, matplotlib is the selected plotting library.In&nbsp;[2]:     import numpy as npimport pandas as pdimport matplotlib.pyplot as plt     In&nbsp;[3]:     x = np.arange(0, 30)y = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70, 75, 88, 81, 87, 95, 100, 108, 135, 151, 160, 169, 179]plt.figure(figsize=(10,6))plt.scatter(x, y)plt.show()             In&nbsp;[4]:     from sklearn.preprocessing import PolynomialFeaturespoly = PolynomialFeatures(degree=2, include_bias=False)poly             Out[4]:PolynomialFeatures(include_bias=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PolynomialFeaturesPolynomialFeatures(include_bias=False)In&nbsp;[5]:     poly_features = poly.fit_transform(x.reshape(-1, 1))     In&nbsp;[6]:     from sklearn.linear_model import LinearRegressionpoly_reg_model = LinearRegression()poly_reg_model.fit(poly_features, y)             Out[6]:LinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()Polynomial features and Linear Regression work together to create the model that fits the points. This way of drawing a curve is a differnt aproach that the one that has been used in graphics development, for the moment we are playing around, and plotting the result.In&nbsp;[7]:     y_predicted = poly_reg_model.predict(poly_features)y_predicted             Out[7]:array([  1.70806452,   3.04187987,   4.70292388,   6.69119657,         9.00669792,  11.64942794,  14.61938662,  17.91657397,        21.54098999,  25.49263467,  29.77150802,  34.37761004,        39.31094073,  44.57150008,  50.1592881 ,  56.07430478,        62.31655014,  68.88602415,  75.78272684,  83.00665819,        90.55781821,  98.4362069 , 106.64182425, 115.17467027,       124.03474495, 133.22204831, 142.73658033, 152.57834101,       162.74733037, 173.24354839])In&nbsp;[8]:     plt.scatter(x,y)plt.plot(x, y_predicted,c=&#39;red&#39;)plt.show()             SPLINE ITERPOLATION&#182;The following cells contains the linear interpolation models for both regular polynomial and spline transformations. Then visualize the model fit to the points with a varying range of degrees.The higher the degree, both the polynomial and spline, the more accurate the model to the points. In a data science approach a lower degree may be better to avoid overfitting, but if we want to use the model for drawing and graphics purpose, a high degree that fits to the points is a great choice. Enjoy the samples below.In&nbsp;[13]:     lw = 2fig, ax = plt.subplots()ax.set_prop_cycle(    color=[&quot;black&quot;, &quot;teal&quot;, &quot;yellowgreen&quot;, &quot;gold&quot;, &quot;darkorange&quot;, &quot;tomato&quot;])# plot training pointsax.scatter(x, y)# fit polinomials:# reshape de x:x = x.reshape(-1, 1)# polynomial featuresfrom sklearn.linear_model import Ridgefrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import PolynomialFeatures# try different degrees to fit polynomials.for degree in [1,2,3, 10]:    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1e-3))    model.fit(x, y)    y_plot = model.predict(x)    ax.plot(x, y_plot, label=f&quot;degree {degree}&quot;)             c:\\Users\\Alberto-PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39773e-33): result may not be accurate.  return linalg.solve(A, Xy, assume_a=&#34;pos&#34;, overwrite_a=True).T        In&nbsp;[14]:     # vs spline fitting to data:# B-spline with 4 + 3 - 1 = 6 basis functionsfrom sklearn.preprocessing import SplineTransformer# fit polynomial:lw = 2fig, ax = plt.subplots()ax.set_prop_cycle(    color=[&quot;black&quot;, &quot;teal&quot;, &quot;yellowgreen&quot;, &quot;gold&quot;, &quot;darkorange&quot;, &quot;tomato&quot;])# plot training pointsax.scatter(x, y)# one more gradex = x.reshape(-1, 1)for degree in [2,5,10]:    # why ridge model¿?    model = make_pipeline(        # spline transfomer cool        SplineTransformer(n_knots=degree, degree=3),         Ridge(alpha=1e-3)    )    model.fit(x, y)    y_plot = model.predict(x)    ax.plot(x, y_plot, label=&quot;B-spline&quot;)    # ax.legend(loc=&quot;lower center&quot;)plt.show()             ",
        "url": "/posts/polinomial-iterpolation.html"
      }
      ,
    
      "posts-jekyll-build-config-html": {
        "title": "Jekyll Build Config",
        "author": "alesteba",
        "category": "",
        "content": "Jekyll is a powerfull tool for building static websites. Simple integration with github-pages, fast building process, multiple plug-ins to extend functionality, are some of the core features that makes it great. Let’s see different techniques to create a solid webpage and speed-up the build process.markdwonMarkdown is a simple languaje to write any kind of post, it is web oriented and supports code display, from many other languajes.When writting blog post markdown is enough since it can be easily rendered into html. One of the key features of the markdown languaje are the tables.Table style data can be easily structured within md notes. Many IDE’s support working with these tables, like vs code|Header1 |Header2  | Header3||--- | --- | ---||**bold style**| `code block`|data3||\\|escape pipe|\\`backtick|data13|            Header1      Header2      Header3                  bold style      code block      data3              |escape pipe      `backtick      data13      This html table can be styled with some css code. Within Jekyll, store static files in the _layouts folder or in some asset folder if it’s pure style code.&lt;style&gt;    table, td, th {    border: 1px solid;    }    table {    width: 100%;    border-collapse: collapse;    }&lt;/style&gt;blog-like design, Jekyll PaginationCertain structure is needed to run a blog like website. Jekyll’s default pagination is not a good a condidate when categories need to be paginated.The following code solves the previous issue when running along the written plug-in here.The url design is the key feature to make categories work, the current design uses page navigation for each category.&lt;link rel=\"stylesheet\" href=\"{{site.url}}/assets/css/paginate.css\"&gt;{% if paginator.total_pages &gt; 1 %}    &lt;div class=\"pages_nav\"&gt;        {% if paginator.previous_page %}            &lt;a href=\"{{site.url}}/{{paginator['category']}}/{{ paginator.previous_page_path }}\"&gt;                &lt;button&gt;&lt;&lt;/button&gt;            &lt;/a&gt;         {% endif %}        {% for page in (1..paginator.total_pages) %}            {% if page == paginator.page %}                &lt;button&gt;{{ page }}&lt;/button&gt;            {% elsif page == 1 %}                &lt;a href=\"{{site.url}}/{{paginator['category']}}/\"&gt;                    &lt;button&gt;{{ page }}&lt;/button&gt;                &lt;/a&gt;            {% else %}                &lt;a href=\"{{site.url}}/{{paginator['category']}}/page{{ page }}\"&gt;                    &lt;button&gt;{{ page }}&lt;/button&gt;                &lt;/a&gt;            {% endif %}        {% endfor %}        {% if paginator.next_page %}            &lt;a href=\"{{site.url}}/{{paginator['category']}}/{{ paginator.next_page_path }}\"&gt;                &lt;button&gt;&gt;&lt;/button&gt;            &lt;/a&gt;         {% endif %}    &lt;/div&gt;{% endif %}metadataMetadata is declared in at the top section of each page, known as front matter. It’s a collection of key-value properties written in YAML.Here is a sample front matter that I’m using on this blog:---layout: post_v2title: \"Jekyll Build Config\"slug: jekyll-build-configdate: 2022-12-25 01:00:00 +0100categories: jekyll website author: waloncabpermalink: /posts/:title.htmlexcerpt_separator: &lt;!--more--&gt;---pluginsThere are a few jekyll plugins that enhance the process. Configure and customize your site with just what is needed.In order to install the plug-ins you have to install the according ruby gems. https://jekyllrb.com/docs/plugins/installation/gem install jekyll-seo-tag            PLUGIN      URL                  target blank      https://github.com/keithmifsud/jekyll-target-blank              jekyll SEO      https://github.com/jekyll/jekyll-seo-tag              jekyll sitemap      https://github.com/jekyll/jekyll-sitemap      When a new plug-in is installed, add it to the page config.yml file in the plugins section. It should look something like this.plugins:- jekyll-feed- jekyll-seo-tag- jekyll-sitemaptitleIn this blog we use a concrete way to generate page titles. Here we see how to create better titles that include the blog name and the current page that is been rendered, it helps SEO engines to positionate. We want the url title to have the following form:    post_name - page_n - site_name{% if page.tag or page.title %}    {% if page.tag %}    {{ page.tag | escape }}    {% else %}    {{ page.title | escape }}    {% endif %}    -{% endif %}{% if paginator and paginator.page and paginator.total_pages &gt; 1 and paginator.page &gt; 1 %}    Page {{ paginator.page }} of {{ paginator.total_pages }} -{% endif %}{{ site.title | escape }}optimizationsTo increase build performance, liquid-c has been installed.It’s a c-based implementation of the liquid parser that’s faster than the one used by Jekyll by default.Target-blank plugin to have external links automatically open in new tabs but also to isolate my site from external sites I link to. It increased build time but the simplicity to open external links is worth it.When writing new articles or updating my blog, I like to preview my changes, before pushing them to the repo. For that, I need just a few recent articles which I can build using:analyticsIn order to integrate google analytics to the blog, add the following code lines to web frame template.&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;&lt;script async src=\"https://www.googletagmanager.com/gtag/js?id=G-GP7FZ2055V\"&gt;&lt;/script&gt;&lt;script&gt;    window.dataLayer = window.dataLayer || [];    function gtag(){dataLayer.push(arguments);}    gtag('js', new Date());    gtag('config', 'G-GP7FZ2055V');&lt;/script&gt;web-structureLayouts and templates make code simple and organized. Simple file organization makecheck https://shopify.github.io/liquid/basics/whitespace/ for white-space control.&lt;body&gt;    &lt;div class=\"content\"&gt;        {% include header_v2.html %}        &lt;br&gt;                {% include nav_v2.html %}        &lt;br&gt;        {{ content }}        &lt;br&gt;        {% include footer_v2.html %}    &lt;/div&gt;&lt;/body&gt;search blog-informationThe small search box in the right bar navigation allows the user to filter the information in the posts. This small feature requires more than expected. SImple HTML code makes the search container, but then another script is needed to query the information and return the mathed searched.&lt;div class=\"topnav\" id=\"myTopnav\"&gt;    &lt;div class=\"search-container\"&gt;        &lt;form action='{{site.url}}/search.html' method=\"get\"&gt;            &lt;input type=\"text\" id=\"search-box\" name=\"query\"&gt;            &lt;!-- &lt;input type=\"submit\" value=\"search\"&gt; --&gt;            &lt;button type=\"submit\" value=\"search\"&gt;Submit&lt;/button&gt;        &lt;/form&gt;    &lt;/div&gt;    &lt;a href=\"javascript:void(0);\" class=\"icon\" onclick=\"myFunction()\"&gt;    &lt;i class=\"fa fa-bars\"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;/div&gt;excerptThe demo section in the blog uses the youtube fingerprints to display the blog-post image.",
        "url": "/posts/jekyll-build-config.html"
      }
      ,
    
      "posts-django-jupyter-notebook-html": {
        "title": "Django + Jupyter Notebooks",
        "author": "alesteba",
        "category": "",
        "content": "In this post we explore how to combine the django framework with jupyter notebooks.Sometimes this way of executing code from within the app can be very usuful to test our models.The following code must be executed in the first cell of each notebook.# Without this, you won't be able to import django modulesimport sys, os, django# Find the project base directoryBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))# Add the project base directory to the sys.pathsys.path.insert(0, BASE_DIR)# The DJANGO_SETTINGS_MODULE has to be set to allow us to access django importsos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"motor_perf.settings\")#  Allow queryset filtering asynchronously when running in a Jupyter notebookos.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"# This is for setting up djangodjango.setup()The Django models is accesible once the environment variable has been set.from django.contrib.auth.models import Userprint(User.objects.all())",
        "url": "/posts/django-jupyter-notebook.html"
      }
      ,
    
      "posts-clustering-html": {
        "title": "Clustering &amp; Dendograms Scikit-learn Python",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-25-clustering                    Agglomerative Clustering recursively merges pair of clusters of sample data; uses linkage distance. In this example we use the iris dataset to see how the algorithm performs with different parameters. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion. The affinity is the metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. If linkage is “ward”, only “euclidean” is accepted. If “precomputed”, a distance matrix (instead of a similarity matrix) is needed as input for the fit method.In&nbsp;[1]:     import numpy as npimport pandas as pd     In&nbsp;[2]:     from matplotlib import pyplot as pltfrom scipy.cluster.hierarchy import dendrogramfrom sklearn.datasets import load_irisfrom sklearn.cluster import AgglomerativeClustering     Load the iris dataset to test the algorithm and then visualize the generated clusters. We previosly know that three is the best number of clusters for the datset, the algorithm and the dendograms should be able to show that result. Changing the distance and the linkage parameters modifies the result, lets visualize it throw the following process.In&nbsp;[3]:     iris_data = load_iris()df = pd.DataFrame(    data=iris_data.data,     columns=iris_data.feature_names)     In&nbsp;[4]:     def plot_dendrogram(model, **kwargs):    # Create linkage matrix and then plot the dendrogram    # create the counts of samples under each node    counts = np.zeros(model.children_.shape[0])    n_samples = len(model.labels_)    for i, merge in enumerate(model.children_):        current_count = 0        for child_idx in merge:            if child_idx &lt; n_samples:                current_count += 1  # leaf node            else:                current_count += counts[child_idx - n_samples]        counts[i] = current_count    linkage_matrix = np.column_stack(        [model.children_, model.distances_, counts]    ).astype(float)    # Plot the corresponding dendrogram    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram    dendrogram(linkage_matrix, **kwargs)     The following code uses the distances and the linkage to plot dendograms asociated to each generated group of clusters.‘ward’ minimizes the variance of the clusters being merged.‘average’ uses the average of the distances of each observation of the two sets.‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.‘single’ uses the minimum of the distances between all observations of the two sets.In&nbsp;[5]:     # parameters to testlinkage = [ 'ward', 'complete', 'average', 'single' ]distances = [ 'euclidean', 'manhattan' , 'cosine' ]fig, axs = plt.subplots(4, 3, figsize=(15, 15))for l in range(len(linkage)):    for d in range(len(distances)):         # ward cant work manhattan and cosine distances        if linkage[l] == 'ward':            if (distances[d] == 'manhattan' or                 distances[d] == 'cosine'):                break        model = AgglomerativeClustering(            distance_threshold=0,             n_clusters=None,             linkage=linkage[l],             affinity=distances[d])        # fit the data        model = model.fit(df)        # print the data:                plot_dendrogram(model, truncate_mode=\"level\", p=3, ax = axs[l][d])             ",
        "url": "/posts/clustering.html"
      }
      ,
    
      "posts-k-means-pll-html": {
        "title": "K-Means Parallel Python Implementation",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-13-k-means-pll                    This post explores the possibilities of a simple k-means implementation. The algorithm uses the center_asignment function with a parallel approach. Take a look at the github links below to see the code and then explore the call graphs for both serial and parallel executions. Python multiprocessing creates an important overload making this implementation useful in big datasets running on propper parallelizable hardware, otherwise the result are worse.GITHUB DIRECT CODE EXEC&#182;To simplify things, direct evaluation of the code from github, check the following links to understand the full algorithm.In&nbsp;[12]:     import urllib.request     In&nbsp;[13]:     # https://github.com/waloncab/k-means-pll/blob/main/k_means_pll.pycode_alg = 'https://raw.githubusercontent.com/waloncab/k-means-pll/main/k_means_pll.py'response = urllib.request.urlopen(code_alg)data = response.read()exec(data)     In&nbsp;[14]:     # https://github.com/waloncab/k-means-pll/blob/main/k_means_wrap.py code_wrap = 'https://raw.githubusercontent.com/waloncab/k-means-pll/main/k_means_wrap.py'response = urllib.request.urlopen(code_wrap)data = response.read()exec(data)     PARALLEL CODE&#182;Lets see the headers of the methods involved in the algorithm execution:In&nbsp;[15]:     def init_centroids_random(datos, k):    \"\"\" init centroids random the first time and then choose based on best inertia\"\"\"    passdef init_centroids_best_inertia(datos, k, rand_iters, dist_func):    \"\"\" centroid coordinates based on the clusters points (mean of those points)\"\"\"    passdef centroid_coords(cluster):    \"\"\"calculate new centroids based on cluster data\"\"\"    passdef centroids_recalculate(clusters):    \"\"\" distance of concrete data point to each of the centroids \"\"\"    passdef centroid_points_dist(point, centroides, dist_func):    \"\"\" returns the list of clustered data to corresponding centroid based on distance \"\"\"    passdef centroid_asignment(datos, centroides, dist_func):    \"\"\" returns the list of clustered data to corresponding centroid based on distance \"\"\"    passdef centroid_asignment_parallel(datos, splits, centroides, dist_func):    \"\"\"parallel implementation of the centroid_asignment function\"\"\"    passdef point_labels_to_clusters(datos, label_mask, k):    \"\"\" returns the k clusters with their correspondent data points \"\"\"    pass     In&nbsp;[16]:     def loop_until_equal_centroids(        datos, clusters, centroides,     max_iters, abs_tol, rel_tol,     dist_func, splits):    \"\"\" loop behaviour, stop based on max_iters, or based on inertia \"\"\"    pass     The following code uses python multiprocessing library to split the data and execute the centroid_asginment function in different threads.In&nbsp;[17]:     def centroid_asignment_parallel(datos, splits, centroides, dist_func):    splitted = np.array_split(datos, splits)    pool = multiprocessing.Pool(splits)    params = []    for x in range(splits):        params.append([splitted[x], centroides, dist_func])    result = pool.starmap(centroid_asignment, params)    pool.close(); pool.join()    res_masks = [res[0] for res in result]    res_inert = [res[1] for res in result]     loss = sum(res_inert) / splits     label_mask = np.array(res_masks).reshape(-1)    return label_mask, loss     IRIS DATASET BASIC TEST&#182;Lets run a basic exemple and classify the data from the iris dataset.In&nbsp;[18]:     import numpy as npimport pandas as pdimport matplotlib.pyplot as plt     In&nbsp;[19]:     from sklearn.datasets import load_irisiris_data = load_iris()df = pd.DataFrame(    data=iris_data.data,     columns=iris_data.feature_names)df             Out[19]:                  sepal length (cm)      sepal width (cm)      petal length (cm)      petal width (cm)                  0      5.1      3.5      1.4      0.2              1      4.9      3.0      1.4      0.2              2      4.7      3.2      1.3      0.2              3      4.6      3.1      1.5      0.2              4      5.0      3.6      1.4      0.2              ...      ...      ...      ...      ...              145      6.7      3.0      5.2      2.3              146      6.3      2.5      5.0      1.9              147      6.5      3.0      5.2      2.0              148      6.2      3.4      5.4      2.3              149      5.9      3.0      5.1      1.8      150 rows × 4 columnsIn&nbsp;[20]:     data_array = np.array(iris_data['data'])     PYCALLGRAPH ALGORITHM VISUALIZATION&#182;In&nbsp;[21]:     # use pycall_graph to plot the call processingfrom pycallgraph import PyCallGraphfrom pycallgraph.output import GraphvizOutputfrom image_notebook import *from IPython.display import Image     In&nbsp;[22]:     graphviz_1 = GraphvizOutput()graphviz_1.output_file = 'pycallgraph_1.png'with PyCallGraph(output=graphviz_1):    kmeans = KMeans_UR(                k=3,        max_iters=500,    )    kmeans.fit(data_array)     In&nbsp;[23]:     html = export_image_html_notebook('./pycallgraph_1.png')IPython.display.HTML(html)             Out[23]:In&nbsp;[24]:     graphviz_2 = GraphvizOutput()graphviz_2.output_file = 'pycallgraph_2.png'with PyCallGraph(output=graphviz_2):    # using the multiprocessing algorithm        kmeans = KMeans_UR(                k=3,        max_iters=500,        splits=2,    )    kmeans.fit(data_array)    # use the second example for taking data:    labels = kmeans.cluster_tags()    cent = (kmeans.centroids())     Run the same algorithm in parallel with two data splits to understand the call overload produced by Python.In&nbsp;[25]:     html = export_image_html_notebook('./pycallgraph_2.png')IPython.display.HTML(html)             Out[25]:We observe that when multiprocessing behaviour is introduced Pyhton creates multiple calls to run different threads. Under a basic laptop or a small dataset the call overload is going to make the algorithm slower. There are some cases where this can get the expected speed-up.larger datasets, the iris dataset is not large enough to increse performace with multiprocessing.specific hardware for working with multiple threads, such as:dedicated GPU (may requiere changes in code to use it)highly parallelizable CPU, like Intel Xeon processor family.PLOT CLUSTERS AND CENTROIDS&#182;Plot the clusters and centroids to visualize the data, if the groups are well defined is because the algorithm is working as expected.In&nbsp;[26]:     from mpl_toolkits import mplot3d# Plot the clustered datafig = plt.figure(figsize = (15, 15))ax = plt.axes(projection =\"3d\") # Creating plotfor i in range(len(kmeans.clusters())):    # metodo para labeling the data:    ax.scatter3D (data_array[:, 0], data_array[:, 1], data_array[:,2], c= labels)ax.scatter(cent[:, 0], cent[:,1], cent[:,2],  marker='*', s=300,  c='r', label='centroid')             Out[26]:&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f5176f0f940&gt;        ",
        "url": "/posts/k-means-pll.html"
      }
      ,
    
      "posts-recursive-graph-neighbours-html": {
        "title": "Recursive Graph Neighbours",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-12-graph-depth                    In&nbsp;[1]:     import networkx as nximport matplotlib.pyplot as plt     In&nbsp;[2]:     G = nx.gnp_random_graph(100, 0.075, seed=None, directed=False)     In&nbsp;[3]:     nx.draw(G)             In&nbsp;[4]:     def neigh(G, node, depth):    node_list = []    if depth==0:        node_list.append(node)    else:        for neighbor in G.neighbors(node):            node_list.append(node)            node_list += neigh(G, neighbor, depth-1)    return list(set(node_list))     In&nbsp;[5]:     # For 10 random nodes, draw their correspondent subgraph with detph 1:import random# crate the figure and axesfig, axes = plt.subplots(2, 5, figsize=(24, 10))# unpack all the axes subplotsaxe = axes.ravel()# matplot with 5X10for i in range(10):    r_node = random.sample(list(G.nodes), 1)    neighbours = neigh(G, node=r_node[0], depth=1)    H = G.subgraph(neighbours)        nx.draw(H,             with_labels=True,             node_size=10,             alpha=1,             linewidths=10,            pos=nx.spring_layout(H),            cmap=plt.get_cmap('jet'),            ax=axe[i])             ",
        "url": "/posts/recursive-graph-neighbours.html"
      }
      ,
    
      "posts-map-filter-reduce-recursive-html": {
        "title": "Recursive / Map - Filter - Reduce",
        "author": "waloncab",
        "category": "",
        "content": "2022-10-03-recursive-definitions                    In&nbsp;[&nbsp;]:     def map_rec(f,l):    if l == []:        return l    else:        h = map_rec(f,l[1:])        h.insert(0,f(l[0]))        return(h)     In&nbsp;[&nbsp;]:     def filter_rec(f, l):    if l == []:        return l    else:        h = filter_rec(f,l[1:])        if f(l[0]):            h.insert(0,l[0])        return(h)     In&nbsp;[&nbsp;]:     def reduce_rec(f, l, s):    if l == []:        return l    elif len(l) == 1:        return f(s, l[0])    else:        l = f(l[0], reduce_rec(f,l[1:],s))        return(l)     ",
        "url": "/posts/map-filter-reduce-recursive.html"
      }
      ,
    
      "posts-clousure-callback-html": {
        "title": "Clousures as Callbacks",
        "author": "alesteba",
        "category": "",
        "content": "2022-10-03-clousure-callback                    Clousere definition:In&nbsp;[&nbsp;]:     def func1():   var = \"Enclosed Function\"   def func2():       var = \"Nested Function\"       print(var)   return func2res = func1()res     Returning a function allows us to execute something previously defined when that process ends.Without actually defining a class, we can group the definition of a procedure and its associated callback function, all in the same block of code.In&nbsp;[1]:     import timedef process_function(p_var):    # some algorithm that takes time.    time.sleep(1)    # callback function to return    def callback(call_param):        print(p_var, str(call_param))    return callback     We use the prevoius code to create 3 diferent calls that take time to complete and then print the result of their coresponding callback functions.In&nbsp;[2]:     # define multiple processesproceses = []for x in range(3):    proceses.append(process_function(x))c1, c2, c3 = proceses# use the callbacksprint(c1('var_call'))print(c2('var_call'))print(c3('var_call'))             0 var_callNone1 var_callNone2 var_callNone",
        "url": "/posts/clousure-callback.html"
      }
      ,
    
      "posts-hide-cells-jupyter-notebook-source-html": {
        "title": "Hide Cells in Jupyter Notebook From Source",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-12-hide_cells_jupyter                    In&nbsp;[6]:     import nbformat as nbffrom glob import globdef hide_cells_jupiter(file_path):    # Text to look for in adding tags    text_search_dict = {        \"# HIDDEN\": \"remove-cell\",  # Remove the whole cell        \"# NO CODE\": \"remove-input\",  # Remove only the input        \"# HIDE CODE\": \"hide-input\"  # Hide the input w/ a button to show    }    ntbk = nbf.read(file_path, nbf.NO_CONVERT)    for cell in ntbk.cells:        cell_tags = cell.get('metadata', {}).get('tags', [])        for key, val in text_search_dict.items():            if key in cell['source']:                if val not in cell_tags:                    cell_tags.append(val)        if len(cell_tags) &gt; 0:            cell['metadata']['tags'] = cell_tags    nbf.write(ntbk, file_path)     In&nbsp;[7]:     import nbformat as nbffrom nbconvert.exporters import HTMLExporterfrom nbconvert.preprocessors import TagRemovePreprocessorfrom traitlets.config import Configimport yamldef basic_config():    # Setup config    c = Config()    c.TagRemovePreprocessor.remove_cell_tags = (\"remove-cell\",)    c.TagRemovePreprocessor.remove_all_outputs_tags = ('remove-output',)    c.TagRemovePreprocessor.remove_input_tags = ('remove-input',)    c.TagRemovePreprocessor.enabled = True     # Configure and run out exporter    c.HTMLExporter.preprocessors = [\"nbconvert.preprocessors.TagRemovePreprocessor\"]    return cdef export_notebook(note_path, out_path, c = basic_config):    # Setup config    c = basic_config()    exporter = HTMLExporter(config=c)    exporter.register_preprocessor(TagRemovePreprocessor(config=c),True)    output = exporter.from_filename(note_path)    # tener mucho cuidado con la estructura del path en el que quiero imprimir.    filepath = out_path    # get YAML:    with open(filepath, \"r\") as f:        # Make a dict from the first YAML block        data = next(yaml.load_all(f, Loader=yaml.FullLoader))        print(data)    # 3 Delete output file content    file = open(filepath, 'w')    file.close()    with open(filepath, 'w', encoding='utf-8') as yaml_file:            yaml_file.write(\"---\" + \"\\n\")            yaml.dump(data, yaml_file)            yaml_file.write(\"---\" + \"\\n\")            yaml_file.write(output[0])     In&nbsp;[8]:     hide_cells_jupiter('./2022-11-12-hide_cells_jupyter.ipynb')     In&nbsp;[9]:     export_notebook('./2022-11-12-hide_cells_jupyter.ipynb', '/mnt/f/S-1.Studio/s.ln_blog/blog/_posts/2022-08-11-hide_cells_jupyter.html')             {&#39;author&#39;: &#39;waloncab&#39;, &#39;categories&#39;: &#39;jekyll&#39;, &#39;date&#39;: &#39;2022-07-29 01:00:00 +0100&#39;, &#39;excerpt_separator&#39;: &#39;&lt;!--more--&gt;&#39;, &#39;layout&#39;: &#39;post_v2&#39;, &#39;permalink&#39;: &#39;/posts/:title.html&#39;, &#39;title&#39;: &#39;Hide Cells in Jupyter Notebook From Source&#39;}",
        "url": "/posts/hide-cells-jupyter-notebook-source.html"
      }
      ,
    
      "posts-latex-markdow-jekyll-html": {
        "title": "LateX for markdown (.md) in Jekyll",
        "author": "alesteba",
        "category": "",
        "content": "This is for anyone looking for how to use lateX whitin markdown (.md) files for jekyll. Jekyll won’t process the latex code, it has to be done in the browser with javascript. Include the following script calling CDN in the layout that contains your blog-post:    &lt;script    src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"    type=\"text/javascript\"&gt;    &lt;/script&gt;\\[W =   \\left[ {\\begin{array}{cc}    0       &amp; -u_{z} &amp;  u_{y}\\\\     u_{z}  &amp; 0      &amp; -u_{z}\\\\    -u_{y}  &amp;  u_{x} &amp;  0  \\end{array} } \\right]\\]\\[I + \\sin(\\theta) \\times W + 2*\\sin^2(\\frac{\\theta}{2})\\]",
        "url": "/posts/latex-markdow-jekyll.html"
      }
      ,
    
      "posts-networkx-graph-traversal-html": {
        "title": "NetworkX Graph Random Walk",
        "author": "alesteba",
        "category": "",
        "content": "graph_traverse                    NetworkX is powerfull python library for working with big graph structures. Let's analyze how to randomly walk directed graphs.In&nbsp;[52]:     import pylab as pimport networkx as nximport numpy as npimport random     In&nbsp;[53]:     G = nx.DiGraph()G.add_edge(\"A\",\"B\")G.add_edge(\"A\",\"H\")G.add_edge(\"H\",\"C\")G.add_edge(\"B\",\"C\")G.add_edge(\"B\",\"D\")nx.draw(G)p.show()             Randomly traversing a graph is a simple task, for the moment let's cover walking for a non-weighted directed graph.give the current_node a start valuefor each step:do an action with the current nodecalculate a new random value to select the next nodeIn&nbsp;[54]:     # randomly traverse all the graph:current_node = 'A'while (True):    # identify current node neighbors    n_list = list(G.neighbors(current_node))    #TODO: whatever action with the current node    print(\"Current Node: \" + current_node)    # break if node doesn't have neighbors    if len(n_list) == 0:        break    # compute next node    rand_index = random.randrange(0, len(n_list))    current_node = n_list[rand_index]                Current Node: ACurrent Node: BCurrent Node: CLet's randomly generate a bigger directed graph and add weight to the edges. Notice that deciding the next node implies calculating a random value using the neighbors edge weights.In&nbsp;[55]:     G = nx.gnm_random_graph(100, 250, seed=None, directed=True)     In&nbsp;[56]:     for node in G.nodes():    neighbors = list(G.neighbors(node))    # random list of numbers to sum-up one    a = np.random.random(len(neighbors))    a /= a.sum()    for e in range(0, len(neighbors)):        cur_node = node        edg_node = neighbors[e]        edg_weig = a[e]        G[cur_node][edg_node]['weight'] = edg_weig     In&nbsp;[57]:     # basic printing, allows a rapid view of how the graph looks in space.nx.draw(G, with_labels = True)p.show()             In&nbsp;[58]:     nx.draw_shell(G, with_labels = True)p.show()             In&nbsp;[59]:     # Now, the previous algorithm needs to be modified to consider the weights in the nodes whenever the next node is going to be calculated.import random# randomly traverse all the graph:def random_walk(G):    current_node = 0    while (True):        # identify current node neighbors        n_list = list(G.neighbors(current_node))        #TODO: whatever action with the current node        print(\"Current Node: \" + str(current_node))        # break if node doesn't have neighbors        if len(n_list) == 0:            break        weights = []        for i in range(0, len(n_list)):            w = G[current_node][n_list[i]]['weight']            weights.append(w)        # random with weights:        # since only one choice is needed take the [0]: function returns a list        current_node = np.random.choice(n_list, 1, p=weights)[0]     In&nbsp;[60]:     random_walk(G)             Current Node: 0Current Node: 11Current Node: 7Current Node: 92Current Node: 88Current Node: 56Current Node: 83Current Node: 40Current Node: 59Current Node: 77Current Node: 76Current Node: 70Current Node: 61Current Node: 41Current Node: 42Current Node: 64Current Node: 85Current Node: 31Current Node: 94Current Node: 95Current Node: 66Current Node: 55Current Node: 62Current Node: 82Current Node: 99Current Node: 80Current Node: 10Current Node: 69Current Node: 2Current Node: 44Current Node: 50Current Node: 25Current Node: 31Current Node: 36Current Node: 71Current Node: 73Current Node: 68Current Node: 83Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 77Current Node: 76Current Node: 11Current Node: 63Current Node: 13Current Node: 71Current Node: 73Current Node: 68Current Node: 83Current Node: 89Current Node: 57This is the randomly traversed path, lets see what happens if executed a second time.In&nbsp;[61]:     random_walk(G)             Current Node: 0Current Node: 11Current Node: 7Current Node: 84Current Node: 97Current Node: 12Current Node: 89Current Node: 57In&nbsp;[62]:     # lets see if I can automate the working with notebooks for jelyll web development:# metadata cells can be edited.# https://thedatafrog.com/en/articles/jupyter-notebooks-web-pages/# https://jupyterbook.org/en/stable/content/metadata.html#jupyter-cell-tags     ",
        "url": "/posts/networkx-graph-traversal.html"
      }
      ,
    
      "posts-random-vector-within-cone-html": {
        "title": "Random Vector within Cone",
        "author": "alesteba",
        "category": "",
        "content": "Rendering engines use Quaterinions for complex rotations in 3D-space. Here, a different approach is going to be use to generate a random vector within a defined cone. Follow the next steps:  Generate a random unit vector.    coneDirection = (pl1- pl2) / np.linalg.norm(coneDirection)    randomVector = v / np.linalg.norm(v)  Project this vector onto the ‘plane’ with the cone’s direction vector as a normal.    projectedVector = randomVector - coneDirection*(np.dot(coneDirection,randomVector))This vector is now perpedicular to the cone's direction, and can be taken as an axis around which to rotate the cone.  Generate a random angle, theta, between 0 and the cone’s maximum angle.    theta = random.uniform(0, self.angle)  Set up a rotation matrix for theta degrees around the axis projectedVector. Rodrigues’ Rotation Formula gives an efficient method for computing the rotation matrix R in 3D-space corresponding to a rotation by an angle theta about a fixed axis specifiedby the unit vector u=(x,y,x) in R^3\\[W =   \\left[ {\\begin{array}{cc}    0       &amp; -u_{z} &amp;  u_{y}\\\\     u_{z}  &amp; 0      &amp; -u_{z}\\\\    -u_{y}  &amp;  u_{x} &amp;  0  \\end{array} } \\right]\\]\\[I + \\sin(\\theta) \\times W + 2*\\sin^2(\\frac{\\theta}{2})\\]The following code translates the math to numpy pyhton arrays.    # rotation matrix:    u_x= projectedVector[0]    u_y= projectedVector[1]    u_z= projectedVector[2]    w = np.array( [        [0, -u_z, u_y],        [u_z, 0, -u_x],        [-u_y ,u_x, 0],    ]).astype(float)    rot_m = np.identity(3) + (math.sin)*w + (2*sin(theta/2) **2)) * np.linalg.matrix_power(w, 2)Rotate the cone’s direction using that matrix.    res_vec = rot_m @ np.array(coneDirection).T",
        "url": "/posts/random-vector-within-cone.html"
      }
      ,
    
      "demos-opengl-transformations-html": {
        "title": "Spline Transformations - Rendering OpenGL",
        "author": "alesteba",
        "category": "",
        "content": "Rendering a spline shape with a dedicated graphics engine written in Python.The scene graph architecture allows to create a custom spline-shape geometry andthen locally transform the entire object with the disered operations.All matrix and vector operations are abstracted by the framework, allowing to translate, rotate and scale from well-defined methods. The stored model matrices are prepared to work with global and local transformations.Read the following post to deeply understand how matrix transformations works:Matrix Transformations for Rendering 3D Objects",
        "url": "/demos/openGL-transformations.html"
      }
      ,
    
      "posts-rendering-engine-architecture-html": {
        "title": "Rendering Engine Architecture",
        "author": "alesteba",
        "category": "",
        "content": "      Graphics Library vs Rendering Engine    OpenGL is a graphics library with many functions for drawing complex geometries based on more simple geometry primitives such as points, lines and triangles.   A rendering engine is a well defined framework that uses some of the graphics library functions to deliver a simple way to construct 3d scenes.   In order to understand the rendering engine architecture, lets have a grasp of what a graphics pipeline looks like.        Graphics Pipeline    The graphics pipeline is the process of turning a 3D model into what the computer displays in the 2D screen.  The pipeline has the following stages:                  application: is executed by the software on the main processor, the CPU, initializing the window where graphics will be displayed during the following steps.                    geometry: determining the position of each vertex of the geometric shapes that need to be rendered, implemented by a program called a vertex shader.                    rasterization: establish the relationship between screen pixels and geometric shapes. It is responsible for the majority of the operations with polygons and their vertices        It can be divided in the following steps:                  [start] in: object coordinates          Model &amp; Camera transformations:          Lighting          Projection          Clipping          Window - view port transformation          [end] out: device (screen) coordinates                            pixel processing: associates each pixel in the render image with a color, involves a program called fragment shader.                  Scene Tree    Prior to any of the rendering steps mentioned before, the rendering engine has to work with some abstract representation of a 3D-scene.  This scene is sometimes structured as a tree since it’s simple to calculate complex transformations applied to object hierarchies.    Within this hierarchy each of the 3D objects must store the following data:          matrix for its local transformation      lis of references to child objects      reference to a parent object        Notice that within the same class, a full tree structure has beend defined. Some of the functions this ‘gameObject’ class needs to have are:          add / remove to manage child / parent objects      worldMatrix to calculate the global position      getChildren to convert the scene tree to a list        With this simple ingridients the tree structure the 3D scene can easily be rendered mantaining each object position relative to parent / child.  Keep in mind that the model matrix (matrix for local transformation) can accumulate the result of many transformations,   this transformations apply to the hierarchy of parent and children.        Model Matrix    It stores the current location, orientation and scale of a ‘gameObject’. The aculmulated transformations end up stored within the matrix data.  Why is so important? The global positions of any of the mesh vertices that may actually be rendered won’t be stored,  they are calculated based on the object model matrix every frame when they need to be rendered on screen.  Have a look at the diferent matrices operations that can take within the object local / global transformations:  Matrix Transformations for Rendering 3D Objects    When transforming a set of points with a matrix:          points are multiplied by the matrix in the vertex shader      new coordinates are passed along to the fragment shader      new coordinates of the points are not permantently stored      ",
        "url": "/posts/rendering_engine_architecture.html"
      }
      ,
    
      "posts-matrix-transformations-html": {
        "title": "Matrix Transformation for Rendering 3D objects",
        "author": "alesteba",
        "category": "",
        "content": "    Transformations are at the core of any rendering engine.     Vectors and matrices are the basic data structures that allow to    design and create functions to transform set of points in certain geometric way. Points / Vectors / Matrices    Both points and vectors are represented by a list of numbers, but they have different geometric interpretations.    Points are simple a defined position in a space but vectors represent a direction within that space.    Matrices are the best mathematical construct to apply transformations to the points and vectors, GPUs are highly optimized    to compute matrix multiplications in parallel. What kind of operations are needed in the 3D space ? Well, in any rendering engine, we require the following:    translation    rotation    scale Keep reding the text and imagine that transformations are applied from the origin of the coordinate system (global coordinates),     we'll consider local transformations later  4x4 Matrix in a 3D Space Homogeneous coordinates are a system of coordinates used in projective geometry.    They have the advantage that the coordinates of points, including points at infinity, can be represented using finite coordinates.    Since translation is not a linear transformation we need to embed 3x3 matrices in a 4x4 matrices, find out why Basic Transformation MatricesFor any given object we need to translate, rotate, and scale. Each one of this scene objects need to store transformation data in a 4x4 matrix. The matrix multiplication allow to easily modify the transformation data the object stores.The following blocks of code create the most basic matrices in numpy arrays.Model Matrix        A matrix is used to store the transformation of any object, but what about the points / vertices of that object in the case that     it renders some kind of mesh ?        Storing the transformation in the model matrix allows :             chain transformations by multiplying the model matrix of the object, the result matrix will store the accumulated transformations.        render a complex mesh without having to store the vertices of the mesh inside the object.    def init_Identity():    return np.array( [        [1, 0, 0, 0],        [0, 1, 0, 0],        [0 ,0, 1, 0],        [0, 0, 0, 1]    ]).astype(float)def init_Translation(x,y,z):    return np.array( [        [1, 0, 0, x],        [0, 1, 0, y],        [0 ,0, 1, z],        [0, 0, 0, 1]    ]).astype(float)    The followings lines of code represent the rotation matrices for the x,y,z axes.    Rotation happens around an axis, and the rotation matrix does not move the axis.    Rotation can be produced around any vector, but we are considering just the rotation around the     basis vectors (axis) since other rotations can be derived later from the world matrix.def init_RotationX(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [1, 0,  0, 0],        [0, c, -s, 0],        [0 ,s,  c, 0],        [0, 0,  0, 1]    ]).astype(float)def init_RotationY(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [ c, 0, s, 0],        [ 0, 1, 0, 0],        [-s ,0, c, 0],        [ 0, 0, 0, 1]    ]).astype(float)def init_RotationZ(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [c, -s, 0, 0],        [s, c, 0, 0],        [0 ,0, 1, 0],        [0, 0, 0, 1]    ]).astype(float)    This scale matrix only accepts one parameter scaling the object uniformly along the x,y, axes.def init_Scale(s):    return np.array( [        [s, 0, 0, 0],        [0, s, 0, 0],        [0 ,0, s, 0],        [0, 0, 0, 1]    ]).astype(float) Local vs Global Coordinates     When we multiply any of the previous matrices by some point we are transforming that point in a global coordinate system (Origin(0,0,0)).     For example, when multiplying a point by the translation matrix the point moves along the basis x,y,z axis.    Local transformations require to define an internal local coordinate system. Origin, orientation, and scale of the    local coordinate axes are chosen for convenience, but usually the center of the object is selected to transform locally. How to use matrix multiplication to perform transformations in Local Coordinate Systems             Let's keep it simple, in order to perform any global transformation we chain matrix multiplications on the left side of expression.        To achieve local transformations just multiply on the right side of the expression.         Keep in mind that matrix multiplication is not commutative: A*B != B*A                 Global Transformation: T3 * T2 * T1 * M(model_matrix)        Local Transformation: M(model_matrix) * T1 * T2 * T3     Perspective Matrix     Perspective matrix for rendering the scene.    Frustum: truncated pyramid that defines the visible region.    Parameters            near / far distance:         angle of view: the angle between from and bottom frustum planes.        aspect ratio: width / height of the rendered image.    def init_Perspective(angleOfView=60, aspectRatio=1, near=0.1, far=1000):    #convert to radians    a = angleOfView *pi/180    d = 1.0 / tan(a/2)    r = aspectRatio    b = (far + near) / (near - far)    c =  2 * far * near / (near - far)    return np.array( [        [d/r, 0, 0, 0],        [0, d, 0, 0],        [0 ,0, b, c],        [0, 0, -1, 0]    ]).astype(float)    Within the spline context, all this properties allow simple and more complex transformations to take place.    Some bezier operations are faster in a matrix form, and whenever a global/local transformation is needed there are matrix multiplications underneath.    Check some of the demos to feel the movement.",
        "url": "/posts/matrix_transformations.html"
      }
      ,
    
      "posts-git-automation-html": {
        "title": "Git Commit Automation with Python",
        "author": "alesteba",
        "category": "",
        "content": "This web page is a small complex piece of software. There are a few layers that composes the web, having jekyll as the backend and standard html, css, and javascript on the front-end. Since jekyll is a lightweight static web page generator, the site has to be built before uploading it to any remote server. This is a very repetitive process that could be automated. In this blog post we are going to see a simple bash script to use git version control and upload the built web-page to github-pages.Steps executed by the script:  use [ jekyll bundle build ] to build the web page into the _site folder.  copy the _site folder to some other folder and start a git repository in there.  automate the git commit with the following lines of code.The following lines specify the basic operations that can be done with your repository. Here, a random word function is being used to generate the commit identification message.The script is hardcoded for whis web-site folder structure, in case of using it modify it to fit your folders.#!/bin/bash# copy the files to the destination foldercp -r ./_site/* ../s.ln_blog_prod;# Save where you are and cd to other dirpushd ../s.ln_blog_prod;pwd;git add .;# list remotegit remote -v;# random txt &amp; numrandomTxt=$(cat /dev/urandom | tr -dc '[:alpha:]' | fold -w ${1:-4} | head -n 1);randomNum=$(cat /dev/urandom | tr -dc '[:digit:]' | fold -w ${1:-4} | head -n 1);echo $randomTxt;echo $randomNum;# create the commitgit commit -m \"$randomTxt$randomNum\";# has to be executed with sudosudo git remote set-url origin git@github.com:waloncab/s.ln_blog;# push to githubgit push -f --set-upstream origin master;# get back where you were at the beginning.popd;",
        "url": "/posts/git_automation.html"
      }
      ,
    
      "posts-plotly-web-export-html-html": {
        "title": "Plotting Splines with Plotly and export into HTML",
        "author": "alesteba",
        "category": "",
        "content": "                                                                                                                This plot has been generated using Plotly. There are many scenarios where a completly graphics engine is not necesary. Static visualization can be accomplished with simple libraries such as this one. Visualizing data is such a required task these days, many applications need it. Here it's done just for fun and to enjoy the delghtfull spline curves. Let's cover the basics of pltly and how to export the generated plots to ann html format so it can be integrated to any web-platform.                Keep in mind what your target platforms for the plots are, and then have a look what fits your project best. In this case plotly instead of matplotlib or seaborn, allow simple html export with the full plotting toolbar. This small features make a difference when it comes to the export, have a look at the  documentation        First, make sure you have installed Plotly in your pyhton enviroment,            pip install plotly                Now we are going to plot the data. Transform it into X and Y components, then use the Plotly commands to setup the axis and show it.        This code has been copied from Jupyter notebook cell, use this notebooks to keep code and plotting data organized before auploading to remote servers.            import plotly.express as px        fig = px.line(        x = np.squeeze(np.asarray(X)),         y = np.squeeze(np.asarray(Y))        )    # scale the axis properly    fig.update_yaxes(        scaleanchor = \"x\",        scaleratio = 1,    )        fig.show()                After plotting the data, we need to export the generated graph to an html format. The following snippet does so.        Notice the flags full_html=False, include_plotlyjs='cdn', they import the library with a CDN generating some lightweight script that can be eassily copied.            fig.write_html(\"./exported/random_0.html\",    full_html=False,    include_plotlyjs='cdn')        Creating Animations           Animations make plotting data more appealing, the following graph uses Plotly animations to move a point along the spline.        There is not much extra code required to create this animation, enjoy the plotting area and then have a look at the source.                                                                                                x = np.squeeze(np.asarray(X))y = np.squeeze(np.asarray(Y))N = 50# Create figurefig = go.Figure(        data=[go.Scatter(x=x, y=y,                     mode=\"lines\",                     line=dict(width=2, color=\"blue\")),          go.Scatter(x=x, y=y,                     mode=\"lines\",                     line=dict(width=2, color=\"blue\"))        ],    layout=go.Layout(        updatemenus=[dict(type=\"buttons\",                          buttons=[dict(label=\"Play\",                                        method=\"animate\",                                        args=[None])])]),                                       )fig.update_yaxes(    scaleanchor = \"x\",    scaleratio = 1,)We duplicate the scatter plot since we want to see the underlying spline when the animation is being played, it is just the way the frameweork works.Then establish the frames for the animations, by traversing N steps.fig.frames =    [go.Frame(        data=[go.Scatter(            # here the spline-framework is being used to generate the proper data            # use your x and y data to create the animation.            move_fwd(list_bezier, itr_step, 5.0),            x= np.asarray(itr_step.get_L().get_point(itr_step.get_T())[0]),            y= np.asarray(itr_step.get_L().get_point(itr_step.get_T())[1]),            mode=\"markers\",            marker=dict(color=\"red\", size=10))])        for k in range(N)]fig.show()",
        "url": "/posts/plotly-web-export-HTML.html"
      }
      ,
    
      "demos-audio-visualization-003-html": {
        "title": "Audio Visualization sp.002",
        "author": "alesteba",
        "category": "",
        "content": "Piano key strokes are more fun when you visualize in some form or another the sound produced.Closed spline shape rendered along this small piano track, notice the small fast waves the contour forms.Very pleasant effect that could be applied to many more music tracks like this.",
        "url": "/demos/audio-visualization-003.html"
      }
      ,
    
      "demos-audio-visualization-002-html": {
        "title": "Audio Visualization sp.002",
        "author": "alesteba",
        "category": "",
        "content": "Everything you see in the video is generated at run-time. This time the audio visualizer uses not just a simple mesh but a line renderer to distinguish the contour of the shape.The drums make the shape generate aggressive but very pleasant curves.",
        "url": "/demos/audio-visualization-002.html"
      }
      ,
    
      "demos-audio-visualization-001-html": {
        "title": "Audio Visualization sp.001",
        "author": "alesteba",
        "category": "",
        "content": "This video demonstrates how frequency bands can be used to make dynamic meshes. The mesh is modified at real-time by a redial disposition of those bands.Notice that the code for this representation is being optimized since modifying a mesh every frame is an expensive task no matter how simple the mesh might be.",
        "url": "/demos/audio-visualization-001.html"
      }
      ,
    
      "demos-breath-animation-html": {
        "title": "Reel Showcase",
        "author": "alesteba",
        "category": "",
        "content": "This time with breathing graphics, real time parallel processing for dynamic spline follow.Closed loop behavior algorithm allows to follow any closed line shape at a constant speed. One big challenge is keep the iteration distance independent from the actual spline path that we’re iterating through.Stay tuned for more videos like this, the spline lab is working on awesome new stuff.",
        "url": "/demos/breath-animation.html"
      }
      ,
    
      "demos-organic-algorithms-html": {
        "title": "Organic Algorithms",
        "author": "alesteba",
        "category": "",
        "content": "    Splines are some of the most organic pieces of graphics sofware you can find out there.    This video is about how to add organic movement to the points conforming the line shape.    Kinematic alogorithms use different interpolation methods to transport the spline dots smothly in space.     When we combine the lerp effect with some random seed generation to determine where to move the desired dot,     we achive some result similar to the one in the video. The spline lab is working on awesome new stuff.",
        "url": "/demos/organic-algorithms.html"
      }
      ,
    
      "demos-motion-graphics-html": {
        "title": "Motion Graphics",
        "author": "alesteba",
        "category": "",
        "content": "    Scaling the project to handle different types of lines and the technology around them.     ollowing path behavior within procedural line animations to make pleasant effects.",
        "url": "/demos/motion-graphics.html"
      }
      ,
    
      "demos-demo-reel-aaa-html": {
        "title": "Reel Showcase",
        "author": "alesteba",
        "category": "",
        "content": "This video shows how the project is growing. Traversing splines in real time is hard, it takes certain amount of computational effort.So in order to handle all of this movement without lag, a parallel approach has been introduced to certain algorithms.",
        "url": "/demos/demo_reel-AAA.html"
      }
      ,
    
      "posts-casteljau-s-algorithm-html": {
        "title": "Casteljau&apos;s Algorithm",
        "author": "alesteba",
        "category": "",
        "content": "Sometimes you need to define n-point curves, and generic bezier may fit your needs in those cases.The following lines of code represent how to design a generic bezier curve, n-grade curve.This algorithm uses recursion to iterate throw the entire interpolation points.Parameters:  points: the vector containing the curve modeling points.  t: the interpolation state [0 - 1]Notice the interpolation parameter t affects the entire curve and it does not dependon the number of points the curve is defined.public static Vector3 getPoint_R (List&lt;Vector3&gt; points, float t){  if (points.Count == 1)  { return points [0]; }  List&lt;Vector3&gt; recursive_call = new List&lt;Vector3&gt; ();  for (int i = 0; i &lt; (points.Count - 1); i++)  {    Vector3 newPoint = (1 - t) * points [i] + t * points [i + 1];    recursive_call.Add(newPoint);  }  return getPoint_R (recursive_call, t);}",
        "url": "/posts/Casteljau&apos;s-Algorithm.html"
      }
      ,
    
      "posts-stiff-image-html": {
        "title": "STIF image classifier",
        "author": "alesteba",
        "category": "",
        "content": "2023-07-25-STIFF_imageIn [1]:import cv2 as cv2In [2]:%%capture! pip install -U \"ray[default]\"! pip install bing-image-downloaderIn [3]:import rayIn [4]:context = ray.init()print(context.dashboard_url)2023-06-11 12:18:14,277\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265 127.0.0.1:8265In this blog post we'll implement an image classification algorithm based on classic machine learning methods. The whole process is based on the STIF detectAndCompute algorithm, we use the image key points to compare images and make predictions. Let's see a basic example.In [5]:from skimage import data, io, filtersimport matplotlib.pyplot as pltimport numpy as npIn [6]:# basic STIF example:In [7]:img1 = data.coffee()gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)sift = cv2.SIFT_create()puntos = sift.detect(gray,None) img2=cv2.drawKeypoints(gray,puntos,outImage=None,color=(255,255,0))plt.imshow(img2)Out[7]:&lt;matplotlib.image.AxesImage at 0x7f261e802a40&gt;First, we need an image dataset that we can use for the experiment, let's begin by writing a web-image-downloader and create the folder structure needed to classify and later predict. For this example we use the Bing image downloader to download multiple images from the web based on simple string queries.In [9]:querys = [\"cofee\", \"plane\"]The following function takes the input directory, reads all images inside it, and creates and output directory with the images splitted in train and test based on an indicated percentaje.In [10]:import osdef split_copy(dir, out, test_split_at = 80):  files = os.listdir(dir)  path_train = os.path.join(out, 'train')  path_test = os.path.join(out, 'test')  if not os.path.exists(path_train):    os.mkdir(path_train)  if not os.path.exists(path_test):    os.mkdir(path_test)  for index in range(len(files)):      filename = files[index]      threshold = (int)(test_split_at * len(files) / 100)       sub_dir =  path_train if (index &lt; threshold) else path_test      if filename.lower().endswith('.jpg'):          import shutil          src = os.path.join(dir, filename)          dst = os.path.join(sub_dir, filename)          shutil.copyfile(src, dst)In [11]:from bing_image_downloader import downloaderdef create_repo(querys, num = 20):  for idx, q in enumerate(querys):    downloader.download(        q,         limit=num,          output_dir='dataset_t',         adult_filter_off=True,         force_replace=False,         timeout=60,         verbose=False)    dataset_t = os.path.join('./dataset_t', q)    dataset_r = os.path.join('./dataset_r', q)    if not os.path.exists(dataset_r):      os.makedirs(dataset_r)    split_copy(dataset_t, dataset_r)  # remove temp folder:  import shutil  try:    shutil.rmtree('./dataset_t')  except OSError as e:      print(\"Error: %s - %s.\" % (e.filename, e.strerror))In [12]:%%capturecreate_repo(querys, 10)In [13]:def STIF_desc_img(img_path):      img2 = cv2.imread(img_path)      gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)    sift = cv2.SIFT_create()    _, t = sift.detectAndCompute(gray,None)     return tThe following method is design to return a collection of arrays that can match the asociated image. Notice that each image contains a matrix with descriptors, we need a list of arrays to asociate the image.In [14]:%%capture! pip install tqdmfrom tqdm import tqdmIn [15]:def feats_directory(dir, feats_all):  for filename in tqdm(os.listdir(dir)):          t_desc = STIF_desc_img(os.path.join(dir, filename))      feats_all.append(t_desc)In [16]:def get_subdir_list (rootdir, sub_fold_name):  dirs_sub = []  for file in os.listdir(rootdir):    dir = os.path.join(rootdir, file)    if os.path.isdir(dir):      path_sub = os.path.join(dir, sub_fold_name)      dirs_sub.append(path_sub)  return dirs_subIn [17]:dirs_train = get_subdir_list(\"./dataset_r\", \"train\"); dirs_traindirs_test = get_subdir_list(\"./dataset_r\", \"test\"); dirs_testOut[17]:['./dataset_r/cofee/test', './dataset_r/plane/test']In [18]:%%timefeats_all = []for dir in dirs_train:  feats_directory(dir, feats_all)100%|██████████| 8/8 [00:16&lt;00:00,  2.02s/it]100%|██████████| 8/8 [00:13&lt;00:00,  1.73s/it]CPU times: user 17.8 s, sys: 5.23 s, total: 23.1 sWall time: 30 sWe have created a local repository with a concrete structure, now weIn [19]:def get_target(dirs):  y = []  for idx_class, dir in enumerate(dirs):    for index in range(len(os.listdir(dir))):      y.append(idx_class)  return yIn [20]:y_train = get_target(dirs_train)y_test = get_target(dirs_test)In [21]:feat_stack = np.vstack(feats_all)In [22]:feat_stack.shapeOut[22]:(65107, 128)In [23]:from sklearn.cluster import MiniBatchKMeans,KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")kmeans = kmeans.fit(feat_stack)In [24]:# visualize cluster centers:kmeans.cluster_centers_Out[24]:array([[14.4897995, 21.393045 , 24.698425 , ..., 12.789873 , 10.885117 ,        13.018521 ],       [60.03194  , 20.94659  ,  6.481902 , ...,  6.8431377,  5.4162893,         7.5311747],       [13.086786 , 10.1923   , 11.730155 , ..., 16.217365 , 14.677135 ,        17.317343 ],       ...,       [11.254995 ,  9.523686 , 14.480013 , ...,  5.6824546, 10.37158  ,        11.07143  ],       [27.440165 , 51.269386 , 43.336205 , ...,  8.680245 ,  5.1672006,         8.536621 ],       [19.475609 ,  8.099141 ,  6.2771745, ..., 19.135801 ,  2.9960146,         4.4309835]], dtype=float32)For any image that has some descriptors, we need to compute his word histogram based on the k-means labels that we have obtained. The k-means predict method returns the asociated cluster or label to each of the images STIF descriptor. The data has to be normalized before the return so we can build up the required matrix later.In [25]:def get_word_hist(kmeans, STIF_desc):  row = np.full(len(np.unique(kmeans.labels_)), 0)  for idx, stif in enumerate(STIF_desc):    desc = np.array(stif).reshape(1,128)    label = kmeans.predict(desc)    row[label] = row[label] +1  # normalize  return row / np.linalg.norm(row)In [26]:# the following parallel exeution represent the building of the histogram matrix needed.# Check how easily we can run remote operations and concatenate the results.remote_word_hist = ray.remote(get_word_hist)mat_2 = ray.get( [remote_word_hist.remote(kmeans, x) for x in feats_all])Now, lets run different machine learning algorithms as a subprocess for the classificator that we are building, then compare the accuracy score obtained for each of them. The class structure allows to embed the concrete algorithm, for example different kmeans can be used  to execute the process and then analize performance. The second parameter for the class constructor is the classification algorithm, check the following examples to understand how the STIFF_classifier and how the predict method is used with a concrete directory.In [27]:from sklearn import svmclasificador = svm.SVC(probability=True)clasificador.fit(mat_2, y_train)Out[27]:SVC(probability=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(probability=True)In [28]:img_path = os.path.join(dirs_test[0], os.listdir(dirs_test[0])[0])t_desc = STIF_desc_img(img_path)w_hist = get_word_hist(kmeans, t_desc)clasificador.predict([get_word_hist(kmeans, t_desc)])Out[28]:array([1])Now, we create some wrapper classes to easily use the algorithms implemented, by using them in a correct way we can implement an elegant pipeline with different classificators and evaluate their precission. Notice that the STIFF_classificator takes to arguments for construction, it needs to use a kmeans implementation as well as classic algorithm for classification, once the histogram matrix is built.In [29]:class STIF_img_classifier():  # construct with algorithms:  def __init__(self, kmeans, cls_alg):    self.kmeans = kmeans    self.cls_alg = cls_alg  # to get the labels form repo:  def labels(self, path_dir):    return get_target(path_dir)  def fit(self, path_dir, y_labels):    # dinamycally decorate histogram_func;    remote_word_hist = ray.remote(get_word_hist)    # save labels:    self.y_labels = y_labels    self.feats_all = []    for dir in path_dir:      feats_directory(dir, self.feats_all)    self.feat_stack = np.vstack(self.feats_all)    self.kmeans.fit(self.feat_stack)    self.mat_word_hist = ray.get([remote_word_hist.remote(self.kmeans, x) for x in self.feats_all])    # # pass labels:    self.cls_alg.fit(self.mat_word_hist, self.y_labels)    return self.cls_alg  def run_cls (self, cls_alg):    # reasign the classifier:    self.cls_alg = cls_alg    self.cls_alg.fit(self.mat_word_hist, self.y_labels)    return self.cls_alg  def predict(self, img_path):    t_desc = STIF_desc_img(img_path)    w_hist = get_word_hist(kmeans, t_desc)    return self.cls_alg.predict([w_hist])In [30]:class IMG_rep_download():  # construct with algorithm:  def __init__(self, querys, n):    self.querys = querys    self.n = n  def download(self):    from bing_image_downloader import downloader    # create the repo with n images for each class query;    create_repo(self.querys, self.n)  def get_train_dirs(self):    return get_subdir_list(\"./dataset_r\", \"train\")  def get_test_dirs(self):    return get_subdir_list(\"./dataset_r\", \"test\")Now, let see a basic example of how to use the previous classes. First we use the downloader to create the repository structure with the desired images. Each of the queries is going to generate train and test subfolders.In [31]:import shutilshutil.rmtree('./dataset_r')In [32]:%%capturer_dwn = IMG_rep_download([\"alhambra gardens\", \"nyc skyline\", \"tokyo street neon\" ], 15)r_dwn.download()In [33]:repo_train = r_dwn.get_train_dirs()repo_test = r_dwn.get_test_dirs()In [34]:from sklearn.cluster import MiniBatchKMeans, KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")svc = svm.SVC(probability=True)stif_cls = STIF_img_classifier(kmeans, svc)labels = stif_cls.labels(repo_train)trained = stif_cls.fit(repo_train, labels)100%|██████████| 12/12 [00:34&lt;00:00,  2.91s/it]100%|██████████| 11/11 [00:24&lt;00:00,  2.25s/it]100%|██████████| 11/11 [00:24&lt;00:00,  2.18s/it]In [35]:img_path = os.path.join(repo_test[0], os.listdir(repo_test[0])[0])p_class = stif_cls.predict(img_path); p_class[0]Out[35]:0Once the STIFF classifier has been trained with the trained dataset, we need to test the performance againts the rest of the data. Since the dataset is already splitted into train/test/, we just need to predict for each of those test images to be able to construct the y_pred arrays that contains the class prediction for the test images.In [36]:@ray.remotedef remote_predict(cls, img):  return cls.predict(img)[0]# get y_pred array for test images:def get_y_pred(cls, test_dir):  img_path = []  # img_paths; and run parallel:  for d in test_dir:    for f in os.listdir(d):      img_path.append(os.path.join(d, f))  # img  y_pred = ray.get( [remote_predict.remote(cls, img) for img in img_path] )  return zip(img_path, y_pred)In [37]:# asign y_true and y_pred;y_true = get_target(repo_test)zipped_preds = get_y_pred(stif_cls, repo_test)img_paths, y_pred = list(zip(*zipped_preds))(raylet) Spilled 2622 MiB, 3 objects, write throughput 78 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.(raylet) Spilled 5244 MiB, 6 objects, write throughput 134 MiB/s.In [38]:rows = 3cols = 3size = rows*cols_, axs = plt.subplots(rows, cols, figsize=(12, 12))axs = axs.flatten()last = size if (len(img_paths) &gt; size) else len(img_paths)for idx in range(last):   img = img_paths[idx]  gray = cv2.imread(img, cv2.IMREAD_GRAYSCALE)  sift = cv2.SIFT_create()  puntos = sift.detect(gray,None)   img2=cv2.drawKeypoints(gray,puntos,outImage=None,color=(255,255,0))  axs[idx].imshow(img2)  axs[idx].set_title(\"class:\" + str(y_pred[idx]))plt.show()In [39]:from sklearn.metrics import accuracy_scoreaccuracy_score(y_true, y_pred)Out[39]:0.8888888888888888Now, let's run different machine learning algorithms as a subprocess for the classificator that we are building, then compare the accuracy score obtained for each of them. The class structure allows to embed the concrete algorithm, for example different classifiers can be used to execute the process and then analyze performance.In [40]:# use same k-means:from sklearn.cluster import MiniBatchKMeans, KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")In [41]:# trainning the base:stif_cls = STIF_img_classifier(kmeans, svm.SVC(probability=True))labels = stif_cls.labels(repo_train)trained = stif_cls.fit(repo_train, labels)100%|██████████| 12/12 [00:34&lt;00:00,  2.85s/it]100%|██████████| 11/11 [00:27&lt;00:00,  2.53s/it]100%|██████████| 11/11 [00:23&lt;00:00,  2.16s/it]In [52]:%%capture# rest of algorithms:from sklearn.neighbors import NearestCentroidalgs = [    svm.SVC(probability=True),     NearestCentroid(),   ]acc_res = {}for al in algs:  # run new classification algorithm over the trainned data:  stif_cls.run_cls(al)  zipped_preds = get_y_pred(stif_cls, repo_test)  img_paths, y_pred = list(zip(*zipped_preds))  score = accuracy_score(y_true, y_pred)  acc_res[al.__class__.__name__ ] = scoreIn [53]:acc_resOut[53]:{'SVC': 1.0, 'NearestCentroid': 0.6666666666666666}",
        "url": "/posts/STIFF_image.html"
      }
      ,
    
      "posts-bezier-matrix-html": {
        "title": "Beizer Matrix Form",
        "author": "alesteba",
        "category": "",
        "content": "In this post we understand how to get a point in a Bezier curve. These curves are about interpolation, the most used ones are cubic bezierssince they can be really good optimized. Given an interpolation parameter t, the coordinates of the respective points can be calculated with a concrete formula.We’ll start by writing the general Bézier formula for a concrete degree. In the plane or in higher-dimensional space, define a 5th order Bézier curve with six points [P0, P1, P2, P3, P4, P5] has the following equation:\\[bezier(t) =  \\\\sum_{k=1}^{5} \\\\binom{5}{k} * (1-t)^{5-k} * t^{k}\\]This equation can be translated into a matrix equivalent, if we keep with the same curve degree, the matrix representation of 5th order Bézier curve with control points is the following:\\[\\begin{multline}  bezier(t) =   \\begin{pmatrix}      t^5 &amp; t^4 &amp; t^3 &amp; t^2 &amp; t^1 &amp;t &amp; 1  \\end{pmatrix} *  \\begin{pmatrix}    -1 &amp; 5 &amp; −10 &amp; 10 &amp; −5 &amp; 1 \\\\    5 &amp; −20 &amp; 30 &amp; −20 &amp;  5 &amp;  0 \\\\     −10 &amp; 30 &amp; −30 &amp; 10 &amp; 0 &amp;  0 \\\\     10 &amp; −20 &amp; 10 &amp; 0 &amp; 0 &amp; 0 \\\\     −5 &amp; 5 &amp;  0 &amp; 0 &amp; 0 &amp; 0 \\\\    1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\  \\end{pmatrix} *  \\begin{pmatrix}      P0 \\\\ P1 \\\\ P2 \\\\ P3 \\\\ P4 \\\\ P5  \\end{pmatrix} \\end{multline}\\]The coefficient matrix of 5th order of Bézier curve. Those coefficients are calculated with the initial letters of 5th order Bézier curve. By looking at the result matrix, we can start to identify how to generalize a method to compute the coefficients for any general degree.\\[\\begin{multline}  bezier(t) =   \\begin{pmatrix}      t^5 \\\\ t^4 \\\\ t^3 \\\\ t^2 \\\\ t^1 \\\\ t \\\\ 1  \\end{pmatrix}^\\top *  \\begin{pmatrix}    - {5 \\choose 0} {5 \\choose 5} &amp; \\hfill {5 \\choose 1} {4 \\choose 4} &amp; - {5 \\choose 2} {3 \\choose 3} &amp; \\hfill {5 \\choose 3} {2 \\choose 2} &amp; - {5 \\choose 4} {1 \\choose 1} &amp; \\hfill {5 \\choose 5} {0 \\choose 0} \\\\    \\hfill {5 \\choose 0} {5 \\choose 4} &amp; - {5 \\choose 1} {4 \\choose 3} &amp; \\hfill {5 \\choose 2} {3 \\choose 2} &amp; - {5 \\choose 3} {2 \\choose 1} &amp; \\hfill {5 \\choose 4} {1 \\choose 0} &amp; 0 \\\\    - {5 \\choose 0} {5 \\choose 3} &amp; \\hfill {5 \\choose 1} {4 \\choose 2} &amp; - {5 \\choose 2} {3 \\choose 1} &amp; \\hfill {5 \\choose 3} {2 \\choose 0} &amp; 0 &amp; 0 \\\\    \\hfill {5 \\choose 0} {5 \\choose 2} &amp; - {5 \\choose 1} {4 \\choose 1} &amp; \\hfill {5 \\choose 2} {3 \\choose 0} &amp; 0 &amp; 0 &amp; 0 \\\\    - {5 \\choose 0} {5 \\choose 1} &amp; \\hfill {5 \\choose 1} {4 \\choose 0} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\    \\hfill {5 \\choose 0} {5 \\choose 0} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\  \\end{pmatrix} *  \\begin{pmatrix}      P0 \\\\ P1 \\\\ P2 \\\\ P3 \\\\ P4 \\\\ P5  \\end{pmatrix} \\end{multline}\\]-&gt; què quiero explicar ¿? -&gt;enlazar al resto de cuadernos que pueda tener :maybe I can clean the notebook up -&gt; and check it this way :render the notebook from other perspective -&gt; i don’t want to ahve multiple sources.descargar y ejecutar o automatizar todo ¿?un disco duro solo para esto ¿?un disco duro solo para la app movimiento ¿? -&gt; o uno separdo para gestionar las cosas ¿?dónde coloco la BD ¿? -&gt; fucked up, y cómo gestionas tantas cosas ¿? -&gt; aquí puedes registrar tu evolución:",
        "url": "/posts/bezier-matrix.html"
      }
      ,
    
      "posts-bezier-curves-html": {
        "title": "Beizer Curves",
        "author": "alesteba",
        "category": "",
        "content": "In this post we understand how to get a point in a Bezier curve. These curves are about interpolation, the most used ones are cubic bezierssince they can be really good optimized. Given an interpolation parameter t, the coordinates of the respective points can be calculated with a concrete formula.Parameters:  t: the interpolation state [0 - 1]  w: weight values in the same dimensions, all x coordinate values, for example.This simple function returns the point coordinate for the interpolation value.However, notice the output and weights are floats, what means that we are constructing the curve for each coordinate independently, {X, Y, Z}public static float Bezier_3 (float t, float[] w){  if (w.Length != 4) {    throw new ArgumentException (\"List should have 4 points to be a cubic bezier\");  }  float t2 = t * t;  float t3 = t2 * t;  float mt = 1-t;  float mt2 = mt * mt;  float mt3 = mt2 * mt;  return w[0]*mt3 + 3*w[1]*mt2*t + 3* w[2]*mt*t2 + w[3]*t3;}Once the parameters are independent from the world-space, we can better optimize and generate concrete bezier functions for 2D or 3D space. Have a detail look on how the previous function is used to construct the curve for 3D space. Now, if the use case is a simple 2D space, we can remove the correspondent weights from the {Z} coordinate.Notice that a reasonable computation time is saved.public static Vector3 getPoint(List&lt;Vector3&gt; points, float t){  if (points.Count != 4) {    throw new ArgumentException (\"List should have 4 points to be a cubic bezier\");  }  float[] w_x = null; float[] w_y = null; float[] w_z = null;  decompose_weight (points, ref w_x, ref w_y, ref w_z);  float x = Bezier_3(t, w_x);  float y = Bezier_3(t, w_y);  float z = Bezier_3(t, w_z);  return new Vector3 (x, y, z);}The decompose weights instructions just reorganizes the List {X;Y;Z} components intoseparated lists containing the individual space coordinate for each one.",
        "url": "/posts/bezier-curves.html"
      }
      ,
    
      "posts-interpolation-spline-html": {
        "title": "Interpoaltion in Graphics",
        "author": "alesteba",
        "category": "",
        "content": "What traversing splines looks like?Interpolation in one of the core features of graphics development, you have it almost in every small tool that the game engine contains.Within the spline framework a linear interpolation is used to traverse shapes. Lets see some of the most relevant types of interpolation:  linear interpolation  polynomial interpolation  spline interpolation  Hermite interpolationDo not mistake the fact that within a spline a linear interpolation is used to go from the start to the end of the curve.In fact we use this linear approach for any iterable line / curve. A spline interpolation could be used to move an object alonga spline.Linear interpolation is the basic tool used in many cases. It interpolates at a constant pace from point a to point b.double interpolate_linear (double y1, double y2, double mu){   return(y1*(1-mu)+y2*mu);}Cubic interpolation is widely used when the movement needs some smooth look (polynomial interpolation).double interpolate_cubic(double y0, double y1, double y2, double y3, double mu){   double a0,a1,a2,a3,mu2;   mu2 = mu*mu;   a0 = y3 - y2 - y0 + y1;   a1 = y0 - y1 - a0;   a2 = y2 - y0;   a3 = y1;   return(a0*mu*mu2+a1*mu2+a2*mu+a3);}What other scenarios is interpolation used?  For any animation whether 2d or 3d, interpolation is used inside the skeleton model.  Inside camera movement interpolation allows smooth follow behavior.  Dynamic movement NPC’s constantly use interpolation to adapt the chasing movement.",
        "url": "/posts/interpolation-spline.html"
      }
      ,
    
      "demos-procedural-terrain-2d-gen-html": {
        "title": "Procedural Terrain 2D Generation",
        "author": "alesteba",
        "category": "",
        "content": "Endless procedural terrain generation in the context of hill racing games. Using procedural content algorithms for line generation and then create terrain mesh along those lines.The hills are rendered after the shape has been created, it is a pleasant effect to watch the car ride the terrain",
        "url": "/demos/procedural-terrain-2D-gen.html"
      }
      ,
    
      "demos-plain-textures-procedural-terrain-html": {
        "title": "Plain-Textures Procedural Terrain",
        "author": "alesteba",
        "category": "",
        "content": "Endless procedural generation in the context of hill racing games. Using procedural content algorithms for line generation and then create biomes along those lines.",
        "url": "/demos/plain-textures-procedural-terrain.html"
      }
      ,
    
      "demos-endless-procedural-generation-html": {
        "title": "Endless Procedural Generation",
        "author": "alesteba",
        "category": "",
        "content": "Endless procedural generation in the context of hill racing games. Using procedural content algorithms for line generation and then create biomes along those lines.The desert is rendered after the shape has been created, then the cactus are placed on the surface with more procedural algorithms to determine the spacing.",
        "url": "/demos/endless-procedural-generation.html"
      }
      
    

  };
</script>

<script src="https://sln-alesteba.github.io/portfolio/assets/js/lunr.min.js"></script>
<script src="https://sln-alesteba.github.io/portfolio/assets/js/search.js"></script>

<!-- https://learn.cloudcannon.com/jekyll/jekyll-search-using-lunr-js/ -->

            <br>

            <div class="footer">

    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/rotate.css">
    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/footer.css">

    <div class="grid-container">

        <div class="item1" id="rotator">
            <img src="https://sln-alesteba.github.io/portfolio/assets/img/fire_buble.png" alt="Walon Cab" width="128" height="128" align="center" class="rotate">
        </div>

        <div class="item2">
            <p class="right">Graphics rendering and spline algorithms. Kinematics from the bezier curves by  traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!</p>

            <p align="center">
                &copy; 2023 alesteba
            </p>
        </div>

        <div class="item3">
            <p>
                Check out some of the resources out there! You'll find graphics, 
                splines, kinematics and code !
            </p>

            <p align="center">
                <a href="https://www.youtube.com/channel/UCJX8AUDFcQJMjY1zRivvZqw" class="fa fa-youtube"></a>
                <a href="https://www.instagram.com/waloncab/" class="fa fa-instagram"></a>
                <a href="https://www.instagram.com/waloncab/" class="fa fa-facebook"></a>
                <a href="https://twitter.com/WalonCab" class="fa fa-twitter"></a>
            </p>
        </div>  

      </div>

</div>

        </div>

    </body>

</html> 