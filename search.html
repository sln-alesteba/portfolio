<!DOCTYPE html>

<html>
    
    <head>
      
        <meta charset=utf-8>

        <!-- check the post for the entire code https://waloncab.github.io/s.ln_blog/posts/jekyll-build-config.html -->

        <title>sln-alesteba:blog </title>
          
        <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="sln-alesteba:blog" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!" />
<meta property="og:description" content="Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!" />
<link rel="canonical" href="https://sln-alesteba.github.io/portfolio/portfolio/search.html" />
<meta property="og:url" content="https://sln-alesteba.github.io/portfolio/portfolio/search.html" />
<meta property="og:site_name" content="sln-alesteba:blog" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="sln-alesteba:blog" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Graphics rendering and spline algorithms. Kinematics from the bezier curves by traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!","headline":"sln-alesteba:blog","url":"https://sln-alesteba.github.io/portfolio/portfolio/search.html"}</script>
<!-- End Jekyll SEO tag -->


        <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/body.css">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-GP7FZ2055V"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-GP7FZ2055V');
        </script>

        <!-- FAVICONS -->

        <link rel="apple-touch-icon" sizes="180x180" href="https://sln-alesteba.github.io/portfolio/assets/fav/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://sln-alesteba.github.io/portfolio/assets/fav/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://sln-alesteba.github.io/portfolio/assets/fav/favicon-16x16.png">
        <link rel="manifest" href="https://sln-alesteba.github.io/portfolio/assets/fav/site.webmanifest">
        <link rel="mask-icon" href="https://sln-alesteba.github.io/portfolio/assets/fav/safari-pinned-tab.svg" color="#5bbad5">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">

    </head>

    <body>

        <div class="content">

            <!-- <div class="header">
         
    <h1>sln-alesteba:blog</h1>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/social.css">
    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/header.css">

    <meta name="viewport" content="width=device-width, initial-scale=1"> 
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.6.js"></script> 


    <script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>

    <script type="importmap">
    {
        "imports": {
        "three": "https://unpkg.com/three/build/three.module.js"
        }
    } 
    </script>

    <p>
        <a href="https://www.youtube.com/channel/UCJX8AUDFcQJMjY1zRivvZqw" class="fa fa-youtube"></a>
        <a href="https://www.instagram.com/sln-alesteba/" class="fa fa-instagram"></a>
        <a href="https://www.instagram.com/walon_cab/" class="fa fa-facebook"></a>
        <a href="https://twitter.com/WalonCab" class="fa fa-twitter"></a>
    </p>

</div>  -->


<div class="header">

    
    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/demos.css">

    <div class="grid-container_demo">

        <div class="item_demo_1">
        
            <!-- <img src="https://img.youtube.com/vi/HO34GNlTT1E/mqdefault.jpg" alt="icon" height="113" width="200"> -->
            <img src="./img/cv.PNG"  width= "100%" height="160"alt="icon">

        </div>
        
        <div class="itemAA_demo_2">

            <p>
                My name is Alberto Esteban, I'm from Logroño, La Rioja a small city in northern Spain. 
                I'm software engineer currently studying a masters in Data Science. 
                I've always been very curious about coding and I've developed a special interest in computer graphics. 
                Right now I'm focusing on learning new things about machine and deep learning, especially from the data architecture perspective.
                (because I belive is pretty similar to the rendering engine pipelines I now.)
            </p>

            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

            <p align="center">
 
                <a href="https://www.youtube.com/channel/UCJX8AUDFcQJMjY1zRivvZqw" class="button"><i class="fa fa-youtube-play" style="font-size:24px"></i></a>
                <a href="https://www.instagram.com/walon_cab/" class="button"><i class="fa fa-instagram" style="font-size:24px"></i></a>
                <a href="https://github.com/waloncab" class="button"><i class="fa fa-github" style="font-size:24px"></i></a>
                <a href="https://huggingface.co/" class="button"><i class="fa fa-area-chart" style="font-size:24px"></i></a>

            </p>
        
        </div>

    </div>

</div>

            <br>
            
            <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/navigation.css">

<!-- https://www.w3schools.com/howto/howto_js_topnav_responsive.asp -->

<div class="topnav" id="myTopnav">

    <!-- <a href="https://sln-alesteba.github.io/portfolio/index.html" class="active">Blog</a>
    <a href="https://sln-alesteba.github.io/portfolio/about">About</a>
    <a href="https://sln-alesteba.github.io/portfolio/demos">Demos</a> -->

    <!-- <ul> -->

        
        
        <a href="https://sln-alesteba.github.io/portfolio/about/">About</a><a href="https://sln-alesteba.github.io/portfolio/blog/">Blog</a><a href="https://sln-alesteba.github.io/portfolio/demos/">Demos</a><a href="https://sln-alesteba.github.io/portfolio/projects/">Projects</a>

    <!-- </ul> -->

    <div class="search-container">

        
        <!-- <form action="/action_page.php">
          <input type="text" placeholder="Search.." name="search">
          <button type="submit">Submit</button>
        </form> -->

        <form action='https://sln-alesteba.github.io/portfolio/search.html' method="get">
            <input type="text" id="search-box" name="query">
            <!-- <input type="submit" value="search"> -->
            <button type="submit" value="search">Submit</button>
        </form>
    </div>

    <a href="javascript:void(0);" class="icon" onclick="myFunction()">
      <i class="fa fa-bars"></i>
    </a>

</div>

<script>
    /* Toggle between adding and removing the "responsive" class to topnav when the user clicks on the icon */
    function myFunction() {
        var x = document.getElementById("myTopnav");
        if (x.className === "topnav") {
            x.className += " responsive";
        } else {
            x.className = "topnav";
        }
    }
</script>

            <br>

            <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/tags.css">

<script src="https://unpkg.com/lunr/lunr.js"></script>

<!-- <form action="/search.html" method="get">
  <label for="search-box">Search</label>
  <input type="text" id="search-box" name="query">
  <input type="submit" value="search">
</form> -->

<ul id="search-results"></ul>

<script>
  window.store = {

    
      "posts-stiff-image-html": {
        "title": "STIF image classifier",
        "author": "alesteba",
        "category": "",
        "content": "2023-07-25-STIFF_imageIn [1]:import cv2 as cv2In [2]:%%capture! pip install -U \"ray[default]\"! pip install bing-image-downloaderIn [3]:import rayIn [4]:context = ray.init()print(context.dashboard_url)2023-06-11 12:18:14,277\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265 127.0.0.1:8265In this blog post we'll implement an image classification algorithm based on classic machine learning methods. The whole process is based on the STIF detectAndCompute algorithm, we use the image key points to compare images and make predictions. Let's see a basic example.In [5]:from skimage import data, io, filtersimport matplotlib.pyplot as pltimport numpy as npIn [6]:# basic STIF example:In [7]:img1 = data.coffee()gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)sift = cv2.SIFT_create()puntos = sift.detect(gray,None) img2=cv2.drawKeypoints(gray,puntos,outImage=None,color=(255,255,0))plt.imshow(img2)Out[7]:&lt;matplotlib.image.AxesImage at 0x7f261e802a40&gt;First, we need an image dataset that we can use for the experiment, let's begin by writing a web-image-downloader and create the folder structure needed to classify and later predict. For this example we use the Bing image downloader to download multiple images from the web based on simple string queries.In [9]:querys = [\"cofee\", \"plane\"]The following function takes the input directory, reads all images inside it, and creates and output directory with the images splitted in train and test based on an indicated percentaje.In [10]:import osdef split_copy(dir, out, test_split_at = 80):  files = os.listdir(dir)  path_train = os.path.join(out, 'train')  path_test = os.path.join(out, 'test')  if not os.path.exists(path_train):    os.mkdir(path_train)  if not os.path.exists(path_test):    os.mkdir(path_test)  for index in range(len(files)):      filename = files[index]      threshold = (int)(test_split_at * len(files) / 100)       sub_dir =  path_train if (index &lt; threshold) else path_test      if filename.lower().endswith('.jpg'):          import shutil          src = os.path.join(dir, filename)          dst = os.path.join(sub_dir, filename)          shutil.copyfile(src, dst)In [11]:from bing_image_downloader import downloaderdef create_repo(querys, num = 20):  for idx, q in enumerate(querys):    downloader.download(        q,         limit=num,          output_dir='dataset_t',         adult_filter_off=True,         force_replace=False,         timeout=60,         verbose=False)    dataset_t = os.path.join('./dataset_t', q)    dataset_r = os.path.join('./dataset_r', q)    if not os.path.exists(dataset_r):      os.makedirs(dataset_r)    split_copy(dataset_t, dataset_r)  # remove temp folder:  import shutil  try:    shutil.rmtree('./dataset_t')  except OSError as e:      print(\"Error: %s - %s.\" % (e.filename, e.strerror))In [12]:%%capturecreate_repo(querys, 10)In [13]:def STIF_desc_img(img_path):      img2 = cv2.imread(img_path)      gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)    sift = cv2.SIFT_create()    _, t = sift.detectAndCompute(gray,None)     return tThe following method is design to return a collection of arrays that can match the asociated image. Notice that each image contains a matrix with descriptors, we need a list of arrays to asociate the image.In [14]:%%capture! pip install tqdmfrom tqdm import tqdmIn [15]:def feats_directory(dir, feats_all):  for filename in tqdm(os.listdir(dir)):          t_desc = STIF_desc_img(os.path.join(dir, filename))      feats_all.append(t_desc)In [16]:def get_subdir_list (rootdir, sub_fold_name):  dirs_sub = []  for file in os.listdir(rootdir):    dir = os.path.join(rootdir, file)    if os.path.isdir(dir):      path_sub = os.path.join(dir, sub_fold_name)      dirs_sub.append(path_sub)  return dirs_subIn [17]:dirs_train = get_subdir_list(\"./dataset_r\", \"train\"); dirs_traindirs_test = get_subdir_list(\"./dataset_r\", \"test\"); dirs_testOut[17]:['./dataset_r/cofee/test', './dataset_r/plane/test']In [18]:%%timefeats_all = []for dir in dirs_train:  feats_directory(dir, feats_all)100%|██████████| 8/8 [00:16&lt;00:00,  2.02s/it]100%|██████████| 8/8 [00:13&lt;00:00,  1.73s/it]CPU times: user 17.8 s, sys: 5.23 s, total: 23.1 sWall time: 30 sWe have created a local repository with a concrete structure, now weIn [19]:def get_target(dirs):  y = []  for idx_class, dir in enumerate(dirs):    for index in range(len(os.listdir(dir))):      y.append(idx_class)  return yIn [20]:y_train = get_target(dirs_train)y_test = get_target(dirs_test)In [21]:feat_stack = np.vstack(feats_all)In [22]:feat_stack.shapeOut[22]:(65107, 128)In [23]:from sklearn.cluster import MiniBatchKMeans,KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")kmeans = kmeans.fit(feat_stack)In [24]:# visualize cluster centers:kmeans.cluster_centers_Out[24]:array([[14.4897995, 21.393045 , 24.698425 , ..., 12.789873 , 10.885117 ,        13.018521 ],       [60.03194  , 20.94659  ,  6.481902 , ...,  6.8431377,  5.4162893,         7.5311747],       [13.086786 , 10.1923   , 11.730155 , ..., 16.217365 , 14.677135 ,        17.317343 ],       ...,       [11.254995 ,  9.523686 , 14.480013 , ...,  5.6824546, 10.37158  ,        11.07143  ],       [27.440165 , 51.269386 , 43.336205 , ...,  8.680245 ,  5.1672006,         8.536621 ],       [19.475609 ,  8.099141 ,  6.2771745, ..., 19.135801 ,  2.9960146,         4.4309835]], dtype=float32)For any image that has some descriptors, we need to compute his word histogram based on the k-means labels that we have obtained. The k-means predict method returns the asociated cluster or label to each of the images STIF descriptor. The data has to be normalized before the return so we can build up the required matrix later.In [25]:def get_word_hist(kmeans, STIF_desc):  row = np.full(len(np.unique(kmeans.labels_)), 0)  for idx, stif in enumerate(STIF_desc):    desc = np.array(stif).reshape(1,128)    label = kmeans.predict(desc)    row[label] = row[label] +1  # normalize  return row / np.linalg.norm(row)In [26]:# the following parallel exeution represent the building of the histogram matrix needed.# Check how easily we can run remote operations and concatenate the results.remote_word_hist = ray.remote(get_word_hist)mat_2 = ray.get( [remote_word_hist.remote(kmeans, x) for x in feats_all])Now, lets run different machine learning algorithms as a subprocess for the classificator that we are building, then compare the accuracy score obtained for each of them. The class structure allows to embed the concrete algorithm, for example different kmeans can be used  to execute the process and then analize performance. The second parameter for the class constructor is the classification algorithm, check the following examples to understand how the STIFF_classifier and how the predict method is used with a concrete directory.In [27]:from sklearn import svmclasificador = svm.SVC(probability=True)clasificador.fit(mat_2, y_train)Out[27]:SVC(probability=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(probability=True)In [28]:img_path = os.path.join(dirs_test[0], os.listdir(dirs_test[0])[0])t_desc = STIF_desc_img(img_path)w_hist = get_word_hist(kmeans, t_desc)clasificador.predict([get_word_hist(kmeans, t_desc)])Out[28]:array([1])Now, we create some wrapper classes to easily use the algorithms implemented, by using them in a correct way we can implement an elegant pipeline with different classificators and evaluate their precission. Notice that the STIFF_classificator takes to arguments for construction, it needs to use a kmeans implementation as well as classic algorithm for classification, once the histogram matrix is built.In [29]:class STIF_img_classifier():  # construct with algorithms:  def __init__(self, kmeans, cls_alg):    self.kmeans = kmeans    self.cls_alg = cls_alg  # to get the labels form repo:  def labels(self, path_dir):    return get_target(path_dir)  def fit(self, path_dir, y_labels):    # dinamycally decorate histogram_func;    remote_word_hist = ray.remote(get_word_hist)    # save labels:    self.y_labels = y_labels    self.feats_all = []    for dir in path_dir:      feats_directory(dir, self.feats_all)    self.feat_stack = np.vstack(self.feats_all)    self.kmeans.fit(self.feat_stack)    self.mat_word_hist = ray.get([remote_word_hist.remote(self.kmeans, x) for x in self.feats_all])    # # pass labels:    self.cls_alg.fit(self.mat_word_hist, self.y_labels)    return self.cls_alg  def run_cls (self, cls_alg):    # reasign the classifier:    self.cls_alg = cls_alg    self.cls_alg.fit(self.mat_word_hist, self.y_labels)    return self.cls_alg  def predict(self, img_path):    t_desc = STIF_desc_img(img_path)    w_hist = get_word_hist(kmeans, t_desc)    return self.cls_alg.predict([w_hist])In [30]:class IMG_rep_download():  # construct with algorithm:  def __init__(self, querys, n):    self.querys = querys    self.n = n  def download(self):    from bing_image_downloader import downloader    # create the repo with n images for each class query;    create_repo(self.querys, self.n)  def get_train_dirs(self):    return get_subdir_list(\"./dataset_r\", \"train\")  def get_test_dirs(self):    return get_subdir_list(\"./dataset_r\", \"test\")Now, let see a basic example of how to use the previous classes. First we use the downloader to create the repository structure with the desired images. Each of the queries is going to generate train and test subfolders.In [31]:import shutilshutil.rmtree('./dataset_r')In [32]:%%capturer_dwn = IMG_rep_download([\"alhambra gardens\", \"nyc skyline\", \"tokyo street neon\" ], 15)r_dwn.download()In [33]:repo_train = r_dwn.get_train_dirs()repo_test = r_dwn.get_test_dirs()In [34]:from sklearn.cluster import MiniBatchKMeans, KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")svc = svm.SVC(probability=True)stif_cls = STIF_img_classifier(kmeans, svc)labels = stif_cls.labels(repo_train)trained = stif_cls.fit(repo_train, labels)100%|██████████| 12/12 [00:34&lt;00:00,  2.91s/it]100%|██████████| 11/11 [00:24&lt;00:00,  2.25s/it]100%|██████████| 11/11 [00:24&lt;00:00,  2.18s/it]In [35]:img_path = os.path.join(repo_test[0], os.listdir(repo_test[0])[0])p_class = stif_cls.predict(img_path); p_class[0]Out[35]:0Once the STIFF classifier has been trained with the trained dataset, we need to test the performance againts the rest of the data. Since the dataset is already splitted into train/test/, we just need to predict for each of those test images to be able to construct the y_pred arrays that contains the class prediction for the test images.In [36]:@ray.remotedef remote_predict(cls, img):  return cls.predict(img)[0]# get y_pred array for test images:def get_y_pred(cls, test_dir):  img_path = []  # img_paths; and run parallel:  for d in test_dir:    for f in os.listdir(d):      img_path.append(os.path.join(d, f))  # img  y_pred = ray.get( [remote_predict.remote(cls, img) for img in img_path] )  return zip(img_path, y_pred)In [37]:# asign y_true and y_pred;y_true = get_target(repo_test)zipped_preds = get_y_pred(stif_cls, repo_test)img_paths, y_pred = list(zip(*zipped_preds))(raylet) Spilled 2622 MiB, 3 objects, write throughput 78 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.(raylet) Spilled 5244 MiB, 6 objects, write throughput 134 MiB/s.In [38]:rows = 3cols = 3size = rows*cols_, axs = plt.subplots(rows, cols, figsize=(12, 12))axs = axs.flatten()last = size if (len(img_paths) &gt; size) else len(img_paths)for idx in range(last):   img = img_paths[idx]  gray = cv2.imread(img, cv2.IMREAD_GRAYSCALE)  sift = cv2.SIFT_create()  puntos = sift.detect(gray,None)   img2=cv2.drawKeypoints(gray,puntos,outImage=None,color=(255,255,0))  axs[idx].imshow(img2)  axs[idx].set_title(\"class:\" + str(y_pred[idx]))plt.show()In [39]:from sklearn.metrics import accuracy_scoreaccuracy_score(y_true, y_pred)Out[39]:0.8888888888888888Now, let's run different machine learning algorithms as a subprocess for the classificator that we are building, then compare the accuracy score obtained for each of them. The class structure allows to embed the concrete algorithm, for example different classifiers can be used to execute the process and then analyze performance.In [40]:# use same k-means:from sklearn.cluster import MiniBatchKMeans, KMeanskmeans = MiniBatchKMeans(        n_clusters=25,    n_init=\"auto\")In [41]:# trainning the base:stif_cls = STIF_img_classifier(kmeans, svm.SVC(probability=True))labels = stif_cls.labels(repo_train)trained = stif_cls.fit(repo_train, labels)100%|██████████| 12/12 [00:34&lt;00:00,  2.85s/it]100%|██████████| 11/11 [00:27&lt;00:00,  2.53s/it]100%|██████████| 11/11 [00:23&lt;00:00,  2.16s/it]In [52]:%%capture# rest of algorithms:from sklearn.neighbors import NearestCentroidalgs = [    svm.SVC(probability=True),     NearestCentroid(),   ]acc_res = {}for al in algs:  # run new classification algorithm over the trainned data:  stif_cls.run_cls(al)  zipped_preds = get_y_pred(stif_cls, repo_test)  img_paths, y_pred = list(zip(*zipped_preds))  score = accuracy_score(y_true, y_pred)  acc_res[al.__class__.__name__ ] = scoreIn [53]:acc_resOut[53]:{'SVC': 1.0, 'NearestCentroid': 0.6666666666666666}",
        "url": "/posts/STIFF_image.html"
      }
      ,
    
      "posts-2-bezier-mat-html": {
        "title": "Bezier Matrix",
        "author": "alesteba",
        "category": "",
        "content": "2023-07-24-2_bezier_MATIn [1]:import scipy.specialimport numpy as npIn this final notebook, we are going to compute the Bézier curves as matrix operations. This approach will make it easier to accelerate the computation, since matrix operations can be easily implemented as CUDA kernels.We'll start by writing the general Bézier formula for a concrete degree. In the plane or in higher-dimensional space, define a 5th order Béziercurve with six points [P0, P1, P2, P3, P4, P5] has the following equation:$$ bezier(t) =  \\sum_{k=1}^{5} \\binom{5}{k} * (1-t)^{5-k} * t^{k}$$This equation can be translated into a matrix equivalent, if we keep with the same curve degree, the matrix representation of 5th order Bézier curve with control points is the following:\\begin{multline}  bezier(t) =   \\begin{pmatrix}      t^5 &amp; t^4 &amp; t^3 &amp; t^2 &amp; t^1 &amp;t &amp; 1  \\end{pmatrix} *  \\begin{pmatrix}    -1 &amp; 5 &amp; −10 &amp; 10 &amp; −5 &amp; 1 \\\\    5 &amp; −20 &amp; 30 &amp; −20 &amp;  5 &amp;  0 \\\\     −10 &amp; 30 &amp; −30 &amp; 10 &amp; 0 &amp;  0 \\\\     10 &amp; −20 &amp; 10 &amp; 0 &amp; 0 &amp; 0 \\\\     −5 &amp; 5 &amp;  0 &amp; 0 &amp; 0 &amp; 0 \\\\    1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\  \\end{pmatrix} *  \\begin{pmatrix}      P0 \\\\ P1 \\\\ P2 \\\\ P3 \\\\ P4 \\\\ P5  \\end{pmatrix} \\end{multline}The coefficient matrix of 5th order of Bézier curve. Those coefficientsare calculated with the initial letters of 5th order Bézier curve. By looking at the result matrix, we can start to identify how to generalize a method to compute the coefficients for any general degree.\\begin{multline}  bezier(t) =   \\begin{pmatrix}      t^5 \\\\ t^4 \\\\ t^3 \\\\ t^2 \\\\ t^1 \\\\ t \\\\ 1  \\end{pmatrix}^\\top *  \\begin{pmatrix}    - {5 \\choose 0} {5 \\choose 5} &amp; \\hfill {5 \\choose 1} {4 \\choose 4} &amp; - {5 \\choose 2} {3 \\choose 3} &amp; \\hfill {5 \\choose 3} {2 \\choose 2} &amp; - {5 \\choose 4} {1 \\choose 1} &amp; \\hfill {5 \\choose 5} {0 \\choose 0} \\\\    \\hfill {5 \\choose 0} {5 \\choose 4} &amp; - {5 \\choose 1} {4 \\choose 3} &amp; \\hfill {5 \\choose 2} {3 \\choose 2} &amp; - {5 \\choose 3} {2 \\choose 1} &amp; \\hfill {5 \\choose 4} {1 \\choose 0} &amp; 0 \\\\    - {5 \\choose 0} {5 \\choose 3} &amp; \\hfill {5 \\choose 1} {4 \\choose 2} &amp; - {5 \\choose 2} {3 \\choose 1} &amp; \\hfill {5 \\choose 3} {2 \\choose 0} &amp; 0 &amp; 0 \\\\    \\hfill {5 \\choose 0} {5 \\choose 2} &amp; - {5 \\choose 1} {4 \\choose 1} &amp; \\hfill {5 \\choose 2} {3 \\choose 0} &amp; 0 &amp; 0 &amp; 0 \\\\    - {5 \\choose 0} {5 \\choose 1} &amp; \\hfill {5 \\choose 1} {4 \\choose 0} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\    \\hfill {5 \\choose 0} {5 \\choose 0} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\  \\end{pmatrix} *  \\begin{pmatrix}      P0 \\\\ P1 \\\\ P2 \\\\ P3 \\\\ P4 \\\\ P5  \\end{pmatrix} \\end{multline}We can write a simple algorithm to generate the coefficient matrix. Let's split the process into two methods, first we create the matrix with the necessary combinatorial numbers, and then we evaluate the matrix to compute the binomial terms at each position.In [2]:def bezier_matrix_binom(grade):  rows =  []  for sub in range(grade + 1):    cols = []    inv = grade - sub    for i in range((grade +1) - sub):      mat = np.array([            [grade, grade -i],            [i,    inv -i]      ])      cols.append(mat)    for j in range(i, (grade)):      cols.append(np.array([            [0, 0],            [0, 0]      ]))    rows.append(cols)  return rowsIn [3]:def bezier_matrix_compute(grade):  rows = bezier_matrix_binom(grade)  m_2 = np.zeros(shape=(grade+1,grade+1))  for sub in range(grade + 1):    mod_grade = (grade +1) % 2    shift = (1 -(sub % 2) ) if mod_grade == 0 else (sub % 2)    for i in range((grade +1) - sub):      sign = 1       if ((i + shift) % 2) != 0:         sign = -1       mat = rows[sub][i]      comb_0 = scipy.special.binom(mat[0][0], mat[1][0])      comb_1 = scipy.special.binom(mat[0][1], mat[1][1])      res = comb_0 * comb_1 * sign      m_2[sub][i] = res  return m_2In [4]:# the method results in the following output:bezier_matrix_compute(8)Out[4]:array([[   1.,   -8.,   28.,  -56.,   70.,  -56.,   28.,   -8.,    1.],       [  -8.,   56., -168.,  280., -280.,  168.,  -56.,    8.,    0.],       [  28., -168.,  420., -560.,  420., -168.,   28.,    0.,    0.],       [ -56.,  280., -560.,  560., -280.,   56.,    0.,    0.,    0.],       [  70., -280.,  420., -280.,   70.,    0.,    0.,    0.,    0.],       [ -56.,  168., -168.,   56.,    0.,    0.,    0.,    0.,    0.],       [  28.,  -56.,   28.,    0.,    0.,    0.,    0.,    0.,    0.],       [  -8.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],       [   1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])Once again, we need to generate some random control points, so we can later fit the curve to those points. To test the matrix we have just calculated, we need to create the two other vector arrays, let's fill some points in space for a low grade curve and check the result.In [5]:# generate n -dimensional control points:import randomdef r_n_dim_control(dim, elems):      N, R = 5, 10    return [random.sample(range((R + 1) * (R + 1)), dim) for _ in range(elems) ]In [6]:points = r_n_dim_control(2, 6)In [7]:i_comps = list(zip(*points))[0]grade = len(i_comps) -1t = 0.5In [8]:t_arr = np.array([[pow(t, grade - i ) for i in range(grade + 1)]]); t_arrOut[8]:array([[0.03125, 0.0625 , 0.125  , 0.25   , 0.5    , 1.     ]])In [9]:mat = np.array(bezier_matrix_compute(grade)); matOut[9]:array([[ -1.,   5., -10.,  10.,  -5.,   1.],       [  5., -20.,  30., -20.,   5.,   0.],       [-10.,  30., -30.,  10.,   0.,   0.],       [ 10., -20.,  10.,   0.,   0.,   0.],       [ -5.,   5.,   0.,   0.,   0.,   0.],       [  1.,   0.,   0.,   0.,   0.,   0.]])In [10]:cmp = np.array([i_comps]); cmp.TOut[10]:array([[79],       [88],       [63],       [31],       [98],       [ 4]])In [11]:# and execute the result:t_arr.dot(mat).dot(cmp.T)Out[11]:array([[61.03125]])In [12]:# sum up previous execution in a single cellgrade = len(i_comps) - 1t_arr = np.array( [[pow(t, grade - i ) for i in range(grade + 1)]] ) mat = np.array( bezier_matrix_compute(grade) ) cmp = np.array([i_comps])res = t_arr.dot(mat).dot(cmp.T)res.reshape(-2)[0]Out[12]:61.03125Ok, the method is working so far, now we can encapsulate the behavior into a single function that can be called for any of the desired coordinate components {x,y,z}, for example. The get_point function takes a point collection with any number of dimensions, inside, a zip method decomposes each of the coordinates to vectorize the point array needed in the matrix multiplication.In [13]:def bezier_mat(grade, t, i_comps, dot):  grade = len(i_comps) - 1  tar = np.array( [[pow(t, grade - i ) for i in range(grade + 1)]] )   mat = np.array( bezier_matrix_compute(grade) )  cmp = np.array( [i_comps] )  r_1 = dot(tar, mat)  r_2 = dot(r_1, cmp.T)  return (float)(r_2[0,0])In [14]:def get_point(points, t, dot):    grade = len(points)-1    i_comps = list(zip(*points))    t_point = [ bezier_mat(grade, t, i_comps[x], dot) for x in range(len(i_comps)) ]    return t_pointIn [15]:curves_control = [r_n_dim_control(3, 8) for _ in range(3)]The get_point function is design to take the matrix dot product as a parameter. This way, if we manage to run accelerated matrix multiplication, we simply can pass the function as a parameter and test performance. The next plots use different dot products, the first one uses the np.dot function and the second uses the Cupy cp.dot that runs on the Nvida T4 that this notebook is using.In [16]:%%timeimport matplotlib.pyplot as pltfig, axs = plt.subplots(1, 3, figsize=(15, 5), subplot_kw=dict(projection='3d'))beziers = [ [ get_point(curves_control[i], t, np.dot) for t in np.linspace(0.0, 1.0, num=100) ] for i in range(3) ]for idx, bezier in enumerate(beziers):    xs, ys, zs = list(zip(*bezier))    axs[idx].plot(xs, ys, zs)plt.show()CPU times: user 857 ms, sys: 197 ms, total: 1.05 sWall time: 972 msIn [17]:from numba import jitfrom numba import cudaIn [18]:# executed in device:In [19]:!nvidia-smiMon Jun 12 15:19:59 2023       +-----------------------------------------------------------------------------+| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||===============================+======================+======================||   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 || N/A   56C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default ||                               |                      |                  N/A |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                                  ||  GPU   GI   CI        PID   Type   Process name                  GPU Memory ||        ID   ID                                                   Usage      ||=============================================================================||  No running processes found                                                 |+-----------------------------------------------------------------------------+In [20]:curves_control = [r_n_dim_control(3, 12) for _ in range(3)]In [21]:import cupy as cpdef cp_dot(A, B):  return cp.matmul(cp.array(A), cp.array(B))In [22]:%%timeimport matplotlib.pyplot as pltfig, axs = plt.subplots(1, 3, figsize=(15, 5), subplot_kw=dict(projection='3d'))beziers = [ [ get_point(curves_control[i], t, cp_dot) for t in np.linspace(0.0, 1.0, num=100) ] for i in range(3) ]for idx, bezier in enumerate(beziers):    xs, ys, zs = list(zip(*bezier))    axs[idx].plot(xs, ys, zs)plt.show()CPU times: user 4.22 s, sys: 755 ms, total: 4.97 sWall time: 9.36 sFinally, we can encapsulate some of the written behavior into a class. Notice from the beginning matrix equation that the coefficient matrix can be computed just once, since the point weights and mainly the t's matrices are the ones changing. If we need to render a common curve, create the control points and compute the coefficient matrix along the split point components for each coordinate, then evaluate the curve for multiple t values (how many t slices will depend on how smooth the result is required).In [23]:# class to wrap matrix computation:from functools import reduceclass Bezier_Matrix():  def __init__(self, grade, dot):    \"\"\" compute matrix and store it \"\"\"    self.grade = grade    self.dot = dot    self.mat = np.array( bezier_matrix_compute(grade) )  def fit (self, points):    \"\"\" fit to the curve control points \"\"\"    self.points = points    self.i_comps = np.array( list(zip(*points)) )    self.n_comps = len(self.i_comps)    return self  def compute (self, t):    \"\"\" evaluate curve at t \"\"\"    self.tar = np.array( [[pow(t, self.grade - i ) for i in range(self.grade + 1)]] )     # reduce pattern to apply dot product:    return [ reduce(self.dot, [self.tar, self.mat, self.i_comps[x].T])[0] for x in range(self.n_comps) ]In [24]:curves_control = [r_n_dim_control(3, 8) for _ in range(3)]In [25]:# elegant way of chaining methods.Bezier_Matrix(7, np.dot).fit(curves_control[0]).compute(0.5)Out[25]:[48.0546875, 74.6015625, 69.125]In [26]:%%timeimport matplotlib.pyplot as pltfig, axs = plt.subplots(1, 3, figsize=(15, 5), subplot_kw=dict(projection='3d'))beziers = [ Bezier_Matrix(7, np.dot).fit(curves_control[i]) for i in range(3)]renders = [ [ beziers[i].compute(t) for t in np.linspace(0.0, 1.0, num=100) ] for i in range(3) ]for idx, render in enumerate(renders):    xs, ys, zs = list(zip(*render))    axs[idx].plot(xs, ys, zs)plt.show()CPU times: user 457 ms, sys: 173 ms, total: 630 msWall time: 448 ms",
        "url": "/posts/2_bezier_MAT.html"
      }
      ,
    
      "posts-1-bezier-cuda-html": {
        "title": "Bezier CUDA",
        "author": "alesteba",
        "category": "",
        "content": "2023-07-24-1_bezier_CUDABézier curves are polynomials of t, they can be implemented using simple polynomials. When a new control point is introduced the curve degree increases making the computational cost rise exponentially. The following code will implement a general method to test n-control points and n-dimension curves. Take a look at the following formulas to see what we need to generalize.$$linear -&gt; (1-t)+t $$$$cuadratic -&gt; (1-t)² + 2 * (1-t)* t + t² $$$$cubic -&gt; (1-t)³ + 3 * (1-t)² * t + 3 * (1-t) * t² + t³$$The following formula generalize the bezier creation with a binomial and a polynomial term, notice this representation works for each of the control point coordinate components. Taking a binomial and then computing the corresponding polynomial will give us a general reusable function.$$ bezier(n,k,t) =  \\sum_{n=1}^{n} \\binom{n}{k} * (1-t)^{n-k} * t^{k}$$In the following cells, we'll see how these simple functions that create the curve can be automatically accelerated by CUDA. This code is especially designed to run on Nvidia hardware, that means that we'll observe better times just on that hardware. Notice how the sum implementation can be easily accelerated with numba.prange instead of regular Python range loop.In [ ]:from numba import jitfrom numba import cudaimport numbaimport numpy as npimport matplotlib.pyplot as pltIn [ ]:@numba.njitdef fact (number):    fact = 1    for i in range(1,number+1):                fact = fact * i    return factIn [ ]:@numba.njitdef binomial(x, y):                return fact(x) // fact(y) // fact(x - y)In [ ]:@numba.njitdef polynomial(n, i, t):    return pow((1 - t), (n - i)) * pow (t, i)In [ ]:@numba.njit(parallel=True)def bezier_func(n, t, w):    sum = 0    for i in numba.prange(0, n+1, 1):              sum += binomial(n, i) * polynomial (n, i, t) * w[i]     return sumWe have seen the required functions to obtain a point on a given bezier curve, but we need some control points to draw the line. We use a random generation approach to hande the control points, we define the generation function based on the number of points we need and the dimension of the points, such as 2D or 3D.In [ ]:# generate n -dimensional control points:def r_n_dim_control(dim, elems):    import random      N, R = 5, 10    res = [random.sample(range((R + 1) * (R + 1)), dim) for _ in range(elems)]    return resIn [ ]:curves_control = [r_n_dim_control(2, 20) for _ in range(3)]In [ ]:fig, axs = plt.subplots(1, 3, figsize=(15, 5))fig.suptitle('Curves Control Points')for idx, control in enumerate(curves_control):    axs[idx].scatter(*zip(*control))Ok, now we need to define the get point function to calculate the point in space based on the control point data and the bezier functions already implemented. Since the implementation can be reused with multiple dimension, the following function unzips the point data for each of its dimensions  (we have different arrays with the x, y, z corresponding values) and then computes the asociated bezier.In [ ]:# plldef get_point(points, t):    grade = len(points)-1    i_comps = list(zip(*points))    t_point = [ bezier_func(grade, t, i_comps[x]) for x in range(len(i_comps)) ]    return t_pointThe following lines contain the splitted execution to handle a 3D point calculation based on some control_points:In [ ]:%timeit b2 = [ get_point(curves_control[0], t) for t in np.linspace(0.0, 1.0, num=1000) ]The slowest run took 4.07 times longer than the fastest. This could mean that an intermediate result is being cached.35.3 ms ± 15.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)In [ ]:%timeit b2 = [ get_point(curves_control[1], t) for t in np.linspace(0.0, 1.0, num=1000) ]The slowest run took 4.02 times longer than the fastest. This could mean that an intermediate result is being cached.70.8 ms ± 37.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)In [ ]:%timeit b2 = [ get_point(curves_control[2], t) for t in np.linspace(0.0, 1.0, num=1000) ]15.5 ms ± 8.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)In [ ]:curves_control = [r_n_dim_control(2, 20) for _ in range(3)]In [ ]:res = [ [ get_point(curves_control[i], t) for t in np.linspace(0.0, 1.0, num=1000) ] for i in range(3) ]In [ ]:fig, axs = plt.subplots(1, 3, figsize=(15, 5))fig.suptitle('Rendering Multiple Curves')for idx, bezier in enumerate(res):    axs[idx].plot(*zip(*bezier))The following bash instructions allow us to compile C++ CUDA code directly from this notebook and then execute the program. The notebook has been executed from Google Colab, below you can see the hardware specifications that we're running on.Now, we reimplemented the previous functions to use CUDA from C++ at the lowest level, then we compare the performance. Notice the only thing suitable for parallel optimization is the sum of the formula. We use the device the best way possible to use each cell in the grid execute an operation. In order to write c++ code from a ipynb notebook we use the magic function %%writefile to save cell code into a file and then compile it with the nvcc nvidia's compiler.In [ ]:!ls /usr/local/bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t sharecolab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  srcIn [ ]:!which nvcc/usr/local/cuda/bin/nvccIn [ ]:!nvidia-smiSun Jun 11 09:33:57 2023       +-----------------------------------------------------------------------------+| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||===============================+======================+======================||   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 || N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default ||                               |                      |                  N/A |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                                  ||  GPU   GI   CI        PID   Type   Process name                  GPU Memory ||        ID   ID                                                   Usage      ||=============================================================================||  No running processes found                                                 |+-----------------------------------------------------------------------------+The following lines of code contain the equivalent c++ implementation to the previous functions written in Python. Just by executing the c++ code we obtain a speed-up, but here we also focus on the required syntax to execute on the nvidia hardware and accelerate with the device. The %%writefile bezier.cu instruction saves the cell code into a file called bezier.cu that can be later compiled.In [ ]:#The bezier.cu programs needs to be executed from python, we need to handle dynamic memory to pass arrays as arguments to the program.In [ ]:%%writefile bezier.cu#include&lt;stdio.h&gt;#include &lt;cmath&gt;#include &lt;iostream&gt;using namespace std;// Returns value of Binomial Coefficient C(n, k)int binomial(int n, int k){    // Base Cases    if (k &gt; n){ return 0; }    if (k == 0 || k == n) { return 1; }    // Recur    return binomial(n - 1, k - 1) + binomial(n - 1, k);}float polynomial(int n, int i, float t){    return pow((1 - t), (n - i)) * pow (t, i);}float bezier(int n, float t, float * w){    float sum = 0;    for (int i = 0; i &lt; (n + 1); i ++ )    {        sum += ( binomial(n, i) * polynomial (n, i, t) * w[i] );    }    return sum;}int main(int argc,char *argv[]){    float * f_weights = new float[argc];    for (int loop = 0; loop &lt; argc; loop++) {              f_weights[loop] = atof(argv[loop]);    }    int n = argc - 1;    float t = 0.5;    float* w = f_weights;    float b = bezier(n, t, f_weights);    cout &lt;&lt; b &lt;&lt; endl;    return 0;}Writing bezier.cuIn [ ]:# we then compile and execute the nvidia accelerated code with the following commads.In [ ]:!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 bezier.cu -o beziernvcc warning : The 'compute_35', 'compute_37', 'sm_35', and 'sm_37' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).bezier.cu(49): warning #177-D: variable \"w\" was declared but never referencedIn [ ]:curves_control = [r_n_dim_control(3, 25) for _ in range(3)]In [ ]:# need to transform float array to single string, this way we can evaluate this string and pass it as a paramter to the bezier program.points_c = list(zip(*curves_control[0]))def float_arr_to_str(arr):  return \" \".join([str(i) for i in arr])In [ ]:# convertbezier_x = \" \".join([str(i) for i in points_c[0]])bezier_y = \" \".join([str(i) for i in points_c[1]])bezier_z = \" \".join([str(i) for i in points_c[2]])In [ ]:%time !./bezier {bezier_x}53.4565CPU times: user 7.04 ms, sys: 58 µs, total: 7.1 msWall time: 305 msIn [ ]:%time !./bezier {bezier_y}64.9291CPU times: user 4.26 ms, sys: 2.06 ms, total: 6.32 msWall time: 306 msIn [ ]:%time !./bezier {bezier_z}74.2294CPU times: user 6.18 ms, sys: 1.06 ms, total: 7.24 msWall time: 305 msAlong the notebook cells we have seen how bezier curves can run in parallel. Our purpose is to run high grade curves to analyze the behaviour, however, we know, from graphics theory, that cubic bezier are the most used to construct splines.We design the bezier program to take the curve weights as parameters into a float array. Since CUDA kernels won't handle STD operations, we need to manage the dynamic memory ourselves. The following code reproduces the early behaviour for the sequential approach.In [ ]:%%writefile bezier_CUDA.cu#include&lt;stdio.h&gt;#include &lt;cmath&gt;#include &lt;iostream&gt;using namespace std;__device__ int binomial(int n, int k){    // Base Cases    if (k &gt; n){ return 0; }    if (k == 0 || k == n) { return 1; }    // Recur    return binomial(n - 1, k - 1) + binomial(n - 1, k);}__device__ float polynomial(int n, int i, float t){    return pow((1 - t), (n - i)) * pow (t, i);}__global__ void bezier(int n, float t, float * w, float * b){    int i = threadIdx.x;    atomicAdd(b, binomial(n, i) * polynomial (n, i, t) * w[i]);    // printf(\"%lf\\n\", *b);}Writing bezier_CUDA.cuIn [ ]:%%writefile -a bezier_CUDA.cuint main(int argc,char *argv[]){    float * f_weights = new float[argc];    // transform input to dynamic float array    for (int loop = 0; loop &lt; argc; loop++) {        f_weights[loop] = atof(argv[loop]);    }    int n = argc - 1;    float t = 0.5;    float *w;    float *b;    int deviceId; cudaGetDevice(&amp;deviceId);    cudaMalloc((void**)&amp;w, argc*sizeof(float));    cudaMallocManaged(&amp;b, sizeof(float));    cudaMemcpy(w, f_weights, argc*sizeof(float), cudaMemcpyHostToDevice);    cudaMemPrefetchAsync(b, sizeof(float), deviceId);    cudaError_t addVectorsErr; cudaError_t asyncErr;    // kernel CUDA call    bezier&lt;&lt;&lt;1, n&gt;&gt;&gt;(n, t, w, b);    addVectorsErr = cudaGetLastError(); asyncErr = cudaDeviceSynchronize();        if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));    if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));    // Data back to host    cudaMemPrefetchAsync(b, sizeof(float), cudaCpuDeviceId);    cout &lt;&lt; b[0] &lt;&lt; endl;    cudaFree(b);    return 0;}Appending to bezier_CUDA.cuIn [ ]:!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 bezier_CUDA.cu -o bezier_CUDAnvcc warning : The 'compute_35', 'compute_37', 'sm_35', and 'sm_37' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).ptxas warning : Stack size for entry function '_Z6bezierifPfS_' cannot be statically determinedIn [ ]:%time !./bezier_CUDA {bezier_x}53.4565CPU times: user 30.2 ms, sys: 10.4 ms, total: 40.6 msWall time: 5.72 sIn [ ]:%time !./bezier_CUDA {bezier_y}64.9291CPU times: user 26.4 ms, sys: 9.93 ms, total: 36.3 msWall time: 5.32 sIn [ ]:%time !./bezier_CUDA {bezier_z}74.2294CPU times: user 25.9 ms, sys: 7.81 ms, total: 33.7 msWall time: 5.32 sOur last example is going to include the C++ and Python code integration. Cuda C++ Kernels can be executed from Python's Pycuda SourceModule. The following code uses the previously defined bezier cuda kernel, and it executes it many times at different t values to render some 3D curves.In [ ]:%%capture ! pip install pycudaIn [ ]:import pycuda.autoinitimport pycuda.driver as drvfrom pycuda.compiler import SourceModuleimport cupy as cpIn [ ]:def get_point_CUDA(points, t):  mod = SourceModule(\"\"\"  __device__ int binomial(int n, int k)  {      if (k &gt; n){ return 0; }      if (k == 0 || k == n) { return 1; }      return binomial(n - 1, k - 1) + binomial(n - 1, k);  }  __device__ float polynomial(int n, int i, float t)  {      return pow((1 - t), (n - i)) * pow (t, i);  }  __global__ void bezier(int n, float t, float * w, float * b)  {      int i = threadIdx.x;      atomicAdd(b, binomial(n, i) * polynomial (n, i, t) * w[i]);  }  \"\"\")  bezier = mod.get_function(\"bezier\")  grade = len(points)-1  i_comps = list(zip(*points))  t_point = []  for w in i_comps:    b = 0.0    # https://forums.developer.nvidia.com/t/passing-scalar-to-functions-cupy-pycuda-scalar-multiplication-of-a-vector/179453    c_b = np.array([b]).astype(np.float32)    c_w = np.array( w ).astype(np.float32)    # CUDA call:    bezier(                 np.int32(grade), np.float32(t), drv.In(c_w), drv.Out(c_b),         block=(grade,1,1), grid=(1,1)    )    t_point.append(c_b[0])  return t_pointIn [ ]:get_point_CUDA(curves_control[0], 0.5)&lt;ipython-input-37-4485e02d5224&gt;:3: UserWarning: The CUDA compiler succeeded, but said the following:ptxas warning : Stack size for entry function 'bezier' cannot be statically determined  mod = SourceModule(\"\"\"Out[ ]:[56.05829, 65.9611, 76.048]In [ ]:# %time b2_CUDA_0 = [ get_point_CUDA(curves_control[0], t) for t in np.linspace(0.0, 1.0, num=100) ]In [ ]:# %time b2_CUDA_1 = [ get_point_CUDA(curves_control[1], t) for t in np.linspace(0.0, 1.0, num=100) ]In [ ]:# %time b2_CUDA_2 = [ get_point_CUDA(curves_control[2], t) for t in np.linspace(0.0, 1.0, num=100) ]In [ ]:# RENDER 3D CURVES AGAIN:In [ ]:import matplotlib.pyplot as pltfig, axs = plt.subplots(1, 3, figsize=(15, 5), subplot_kw=dict(projection='3d'))beziers = [ [ get_point_CUDA(curves_control[i], t) for t in np.linspace(0.0, 1.0, num=25) ] for i in range(3) ]for idx, bezier in enumerate(beziers):    xs, ys, zs = list(zip(*bezier))    axs[idx].plot(xs, ys, zs)plt.show()",
        "url": "/posts/1_bezier_CUDA.html"
      }
      ,
    
      "posts-0-bezier-pll-html": {
        "title": "Bezier Parallel",
        "author": "alesteba",
        "category": "",
        "content": "2023-07-24-0_bezier_PLLIntroduction¶In this publication, we are going to understand how general Bézier curves are created, and we'll implement different parallel algorithms to make them run faster. The aim of this post is to handle general curves, that means that we need the mathematical tools to create them. You may be familiar with some code targeting these curves, especially for cubic Béziers (since they are the most used ones), here we design the following algorithms for n-curve points and n-dimensions, and we'll use them in 2D and 3D scenarios.In [1]:%%capture# we'll be using python's Ray multiprocessing framework:! pip install -U ray[default]import raycontext = ray.init()In [11]:print(context.dashboard_url)127.0.0.1:8265Control Points¶Let's start by creating random points in space that will later conform the curve control points. We define a function that takes the number of points for the curve and the dimension of the space (again, its use will make sense for 2 or 3 dimensions, but you can try it with more). Bézier curves touches the first and last control points, the rest of them act as tensors that create the curve shape.In [12]:import randomimport numpy as npimport matplotlib.pyplot as pltIn [13]:# generate n -dimensional control points:def r_n_dim_control(dim, elems):      N, R = 5, 10    return [random.sample(range((R + 1) * (R + 1)), dim) for _ in range(elems) ]In [14]:# generate linear random 2D control points:def l_2_dim_control(elems):    x = list(np.arange(0, elems))    y = [random.randrange(0, 5) for _ in range(elems)]    return list(zip(x,y))In [15]:points = r_n_dim_control(2, 25)We can take two different approaches to render a bezier curve along the control points created. The first one will use the Casteljau's algorithm to recursively calculate the interpolation point on the curve. The second will handle the interpolation based on a more symbolic / analytical way.The point of this article is to compare these two algorithms when used with many control points. In any case possible, a parallel implementation is going to be compared with the sequential algorithm, take a look at the execution times along the notebook and make your own conclusions.Casteljau's algorithm¶The Casteljau's algorithm takes a completely geometric approach to calculate the interpolated point in the curve. The easiest way to implement is by using its recursive version, it can take some time but for lower grade curves success as quadratic or cubic is more than enough.In [16]:import numpy as npdef point_2_point_interpolation(p1, p2, t):    return (1 - t) * p1 + t * p2In [17]:# casteljaus:def get_point_R (points, t):    if (len(points) == 1) :         return points [0]    # ELSE    recursive_call = []    for i in range(0, len(points) -1):        # this operation has to work for any dimension:        # we use numpy arrays and the operations are redefined:        newPoint = (1 - t) * points [i] + t * points [i + 1]        recursive_call.append(newPoint)    return get_point_R (recursive_call, t)Let's take a look at how the algorithm uses control points recursively to finally return the interpolation point (t) in the curve defined by those points. In order to generate the curve, a bunch of points need to be computed, the next 'for' statement generates 1000 evenly space t values to calculate the desired points at the curve t positions.In [18]:%%timebezier = []for t in np.linspace(0.0, 1.0, num=1000):    p = get_point_R(np.array(points), t)    bezier.append(p)CPU times: total: 2.66 sWall time: 3.24 sIn [19]:plt.plot(*zip(*bezier))Out[19]:[&lt;matplotlib.lines.Line2D at 0x2a792db36d0&gt;]In [20]:from ray.util.multiprocessing import Poolfrom ray import available_resourcescores = int(available_resources()['CPU'])pool = Pool(cores)params = []for t in np.linspace(0.0, 1.0, num=1000):    params.append([np.array(points), t])def f(args):    points, t = args    return get_point_R(points, t)bezier = pool.map(f, params)In [21]:plt.plot(*zip(*bezier))Out[21]:[&lt;matplotlib.lines.Line2D at 0x2a792f322b0&gt;]Finally, we are going to see how nested parallelism can be used to render multiple curves at once. Let's redesign the previous code to run within nested pools.In [22]:def bezier_render(map_func, points, n):    params = []    for t in np.linspace(0.0, 1.0, num=n):        params.append([np.array(points), t])    def pll_point_R(args):        points, t = args        return get_point_R(points, t)    return map_func(pll_point_R, params)In [23]:curves_control = [r_n_dim_control(2, 25) for _ in range(3)]In [24]:# visualize 3 curves running in parallel.from ray.util.multiprocessing import Poolpool1 = Pool()pool2 = Pool()fig, axs = plt.subplots(1, 3, figsize=(15, 5))# change figsize; pero listo,fig.suptitle('Rendering Multiple Curves')params = []for control in curves_control:    params.append([pool2.map, control, 1000])# lista compresión con esto;def pll_render(args):    func, points, n = args    return bezier_render(func, points, n)res = pool1.map(pll_render, params)for idx, bezier in enumerate(res):    axs[idx].plot(*zip(*bezier))2023-06-09 16:25:38,385\tWARNING worker.py:2019 -- WARNING: 16 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).Aanalytic Approach¶Bézier curves are polynomials of t, they can be implemented using simple polynomials, increasing the degree when a new control point is introduced. However, here we need the more general approach to test n-control points and n-dimension curves. Take a look at the following formulas.$$linear -&gt; (1-t)+t $$$$cuadratic -&gt; (1-t)² + 2 * (1-t)* t + t² $$$$cubic -&gt; (1-t)³ + 3 * (1-t)² * t + 3 * (1-t) * t² + t³$$For each of the formulas described, there are two general patterns that we can identify. The binomial terms follow a unique pattern that can be easily computed and the polynomials, if we substitute (1-t) for 'a' and t for 'b' we see another recursive pattern that can be summarized in an elegant formula.$$linear -&gt; 1+1$$$$quadratic -&gt; 1+2+1 $$$$cubic -&gt; 1+3+3+1$$Rename (1-t) to a and t to b, and removing the weights used for the binomial calculations, we get this pattern for each of the curves (understanding the way each grade works allows us to write the general pattern to be reused for n-grade curves):$$linear -&gt; a+b $$$$quadratic -&gt; a²+a* b²+b$$$$cubic -&gt; a³+ a²*b + a*b²+ b³$$Those patterns described above generate the following formula, notice this representation works for each of the control point coordinate components. Taking a binomial and then computing the corresponding polynomial will give us a general reusable function.$$ bezier(n,k,t) =  \\sum_{n=1}^{n} \\binom{n}{k} * (1-t)^{n-k} * t^{k}$$Since the previous formula needs to be calculated for each coordinate component (x,y,z), we can further parallelize calculating those components individually. This analytic formulation allows more granularity, and it will be used within the rendering technique.Working from python, the standard multiprocessing library won't be enough, it can't handle nested parallelism. We use Ray for working with distributed computing and implement the map-reduce pattern to handle the parallel behavior needed.The following functions represent the building blocks for the written formula. Notice there are heavy math operations such as factorials (used for binomial coefficient calculations)In [25]:def fact(number):    fact = 1    for i in range(2,number+1):                fact = fact * i    return factIn [26]:def binomial(x, y):                return fact(x) // fact(y) // fact(x - y)In [27]:def polynomial(n, i, t):    return pow((1 - t), (n - i)) * pow (t, i)In [28]:def bezier_func(n, t, w):    sum = 0    for i in range(0, n+1, 1):        sum += binomial(n, i) * polynomial (n, i, t) * w[i]     return sumIn [29]:bezier_func(10, 0.5, list(zip(*points))[0])Out[29]:73.123046875In [30]:def get_point_sec(points, t):    grade = len(points)-1    i_comps = list(zip(*points))    t_point = [ bezier_func(grade, t, i_comps[x]) for x in range(len(i_comps)) ]    return t_pointIn [31]:b2 = [ get_point_sec(points, t) for t in np.linspace(0.0, 1.0, num=1000) ]In [32]:plt.plot(*zip(*b2))Out[32]:[&lt;matplotlib.lines.Line2D at 0x2a79326bf40&gt;]The following function uses ray's multiprocessing to parallel execute the Bézier function. The way the parameters are passed to the map-reduce behaviour is pretty elegant since list comprehension can be used to mimic the sequential function header.To be able to execute in parallel with ray, the function needs to be decorated with the @ray.remote annotation. Here, we do it dynamically since we also use the function in the previous sequential approach.In [33]:# dinamycall decorate bezier_func;bezier_func = ray.remote(bezier_func)In [34]:def get_point_pll(points, t):    grade = len(points)-1    i_comps = list(zip(*points))    t_point = ray.get( [bezier_func.remote(grade, t, i_comps[x]) for x in range(len(i_comps))] )    return t_pointOnce the point calculation is parallelized, we proceed to render the curve. First let's make a sequential approach and then we will rewrite it to also run in parallel. The ray architecture simply allows us to run nested parallel algorithms. We can abstract each individual process in a map-reduce and let the framework manage the hardware resources to run it.In [35]:%%time# secuentialbezier = [get_point_pll(points, t) for t in np.linspace(0.0, 1.0, num=10)]2023-06-09 16:25:57,945\tWARNING worker.py:2019 -- WARNING: 24 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).CPU times: total: 203 msWall time: 6.23 sIn [36]:# decorate function before use it in parallel.get_point_pll = ray.remote(get_point_pll)In [37]:%%timeimport timebezier = ray.get( [get_point_pll.remote(points, t) for t in np.linspace(0.0, 1.0, num=1000) ] )2023-06-09 16:26:04,547\tWARNING worker.py:2019 -- WARNING: 30 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).2023-06-09 16:26:11,742\tWARNING worker.py:2019 -- WARNING: 32 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).2023-06-09 16:26:21,199\tWARNING worker.py:2019 -- WARNING: 38 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).CPU times: total: 2.91 sWall time: 41.4 sIn [38]:plt.plot(*zip(*bezier))Out[38]:[&lt;matplotlib.lines.Line2D at 0x2a7932eb490&gt;]As a final exercise we can visualize the distributed process in a local machine. Taking consideration that this task can be easily executed in remote clusters for better performance, the local overhead is not considered.In [39]:points_3D = r_n_dim_control(3, 25)In [40]:def render_bezier_analytic (points):    return ray.get( [get_point_pll.remote(points, t) for t in np.linspace(0.0, 1.0, num=1000) ] )In [41]:render_bezier_analytic = ray.remote(render_bezier_analytic)In [42]:points_3D_3 = [ r_n_dim_control(3, 25) for _ in range(3) ]In [43]:import matplotlib.pyplot as pltfig, axs = plt.subplots(1, 3, figsize=(15, 5), subplot_kw=dict(projection='3d'))beziers = ray.get( [ render_bezier_analytic.remote(points_3D_3[x]) for x in range(3) ] )for idx, bezier in enumerate(beziers):    xs, ys, zs = list(zip(*bezier))    axs[idx].plot(xs, ys, zs)plt.show()2023-06-09 16:27:06,672\tWARNING worker.py:2019 -- WARNING: 40 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).2023-06-09 16:27:17,009\tWARNING worker.py:2019 -- WARNING: 44 PYTHON worker processes have been started on node: fd0df0a0701e2678216c477c50444b5801226a73a6d66ed2bc8696c0 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).Since we are running a lot of parallel tasks, Ray dashboard allows us to visualize the task execution and the nested dependencies between the tasks. This example illustrates how to use distributed computing to calculate Bézier point coordinates and then render curves by giving different interpolation values.",
        "url": "/posts/0_bezier_PLL.html"
      }
      ,
    
      "posts-nerf-ficus-html": {
        "title": "NeRF - A concrete example, Ficus",
        "author": "alesteba",
        "category": "",
        "content": " \tNeRF proposes an ingenious way to synthesize novel views of a scene by modelling the volumetric scene function through a neural network. \tThe network learns to model the volumetric scene, thus generating novel views (images) of the 3D scene that the model was not shown at training time.",
        "url": "/posts/NeRF_ficus.html"
      }
      ,
    
      "posts-lof-outlier-pipeline-html": {
        "title": "LOF Outlier Imblearn Pipeline",
        "author": "alesteba",
        "category": "",
        "content": "2023-03-11-LOF-outlier-pipeline                    In this post we examine how to append a local outlier factor method to a regular pipeline, but using imblearn ones.Lets review how to use pipelines when the shape of the dataset need to be modified, such as with outlier removal.In&nbsp;[17]:     import pandas as pdimport numpy as np     In&nbsp;[18]:     # import a basic dataset.df = pd.read_csv(&#39;data/housing.csv&#39;, na_values=&#39;?&#39;)df.head()             Out[18]:                  0.00632      18.00      2.310      0      0.5380      6.5750      65.20      4.0900      1      296.0      15.30      396.90      4.98      24.00                  0      0.02731      0.0      7.07      0      0.469      6.421      78.9      4.9671      2      242.0      17.8      396.90      9.14      21.6              1      0.02729      0.0      7.07      0      0.469      7.185      61.1      4.9671      2      242.0      17.8      392.83      4.03      34.7              2      0.03237      0.0      2.18      0      0.458      6.998      45.8      6.0622      3      222.0      18.7      394.63      2.94      33.4              3      0.06905      0.0      2.18      0      0.458      7.147      54.2      6.0622      3      222.0      18.7      396.90      5.33      36.2              4      0.02985      0.0      2.18      0      0.458      6.430      58.7      6.0622      3      222.0      18.7      394.12      5.21      28.7      In&nbsp;[19]:     # define target variable     In&nbsp;[20]:     # https://www.kaggle.com/code/jonaspalucibarbosa/removing-outliers-within-a-pipeline# interquartile mehtod for outlier detectiondef customsampler_IQR (X, y):        features = X.columns    df = X.copy()    df[&#39;Outcome&#39;] = y        indices = [x for x in df.index]        out_indexlist = []            for col in features:               Q1 = np.nanpercentile(df[col], 25.)        Q3 = np.nanpercentile(df[col], 75.)                cut_off = (Q3 - Q1) * 1.5        upper, lower = Q3 + cut_off, Q1 - cut_off                        outliers_index = df[col][(df[col] &lt; lower) | (df[col] &gt; upper)].index.tolist()        outliers = df[col][(df[col] &lt; lower) | (df[col] &gt; upper)].values                out_indexlist.extend(outliers_index)            out_indexlist = list(set(out_indexlist))        clean_data = np.setdiff1d(indices,out_indexlist)    return X.loc[clean_data], y.loc[clean_data]     In&nbsp;[21]:     last_ix = len(df.columns) - 1X = df.drop(df.columns[last_ix], axis=1)y = df[df.columns[last_ix]]print(X.shape, y.shape)             (505, 13) (505,)Now we can use an imblearn pipeline (since the shape of the y can be changed) and apply the transformation to the original dataset.The usage of the previous defined function is straightforward, create a new step and embed it into a FunctionSampler.In&nbsp;[22]:     # use of imblearn pipelinesfrom sklearn.model_selection import train_test_splitfrom imblearn.pipeline import Pipelinefrom imblearn import FunctionSampler# define the pipelineclf = Pipeline(    steps=[        (&#39;o&#39;, FunctionSampler(func=customsampler_IQR, validate = False))    ])clf.fit(X, y)X_enc, y_enc = clf.fit_resample(X, y)X_enc.shape             Out[22]:(274, 13)In&nbsp;[23]:     X_enc             Out[23]:                  0.00632      18.00      2.310      0      0.5380      6.5750      65.20      4.0900      1      296.0      15.30      396.90      4.98                  0      0.02731      0.0      7.07      0      0.469      6.421      78.9      4.9671      2      242.0      17.8      396.90      9.14              1      0.02729      0.0      7.07      0      0.469      7.185      61.1      4.9671      2      242.0      17.8      392.83      4.03              2      0.03237      0.0      2.18      0      0.458      6.998      45.8      6.0622      3      222.0      18.7      394.63      2.94              3      0.06905      0.0      2.18      0      0.458      7.147      54.2      6.0622      3      222.0      18.7      396.90      5.33              4      0.02985      0.0      2.18      0      0.458      6.430      58.7      6.0622      3      222.0      18.7      394.12      5.21              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              500      0.06263      0.0      11.93      0      0.573      6.593      69.1      2.4786      1      273.0      21.0      391.99      9.67              501      0.04527      0.0      11.93      0      0.573      6.120      76.7      2.2875      1      273.0      21.0      396.90      9.08              502      0.06076      0.0      11.93      0      0.573      6.976      91.0      2.1675      1      273.0      21.0      396.90      5.64              503      0.10959      0.0      11.93      0      0.573      6.794      89.3      2.3889      1      273.0      21.0      393.45      6.48              504      0.04741      0.0      11.93      0      0.573      6.030      80.8      2.5050      1      273.0      21.0      396.90      7.88      274 rows × 13 columnsAnd finally, we use it with a machine learning model. The process is completly reusable, just add another step to the pipeline after the IQR method.The following cell uses imputaton strategies, data scalation and a simple LinearDiscriminantAnalysis at the end of the preprocess transformations.In&nbsp;[24]:     from imblearn import FunctionSamplerfrom imblearn.pipeline import pipeline     In&nbsp;[25]:     from sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.impute import SimpleImputerfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_scorefrom sklearn.preprocessing import MinMaxScaler     In&nbsp;[&nbsp;]:     model = LinearDiscriminantAnalysis()strategies = [&#39;mean&#39;, &#39;median&#39;, &#39;most_frequent&#39;, &#39;constant&#39;]  trans = MinMaxScaler()results = []for s in strategies:    # create the modeling pipeline    pipe = Pipeline(        steps=[            (&#39;o&#39;, FunctionSampler(func=customsampler_IQR, validate = False)),            (&#39;i&#39;, SimpleImputer(strategy=s)),            (&#39;t&#39;, trans),               (&#39;m&#39;, model),        ])        # evaluate the model    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1)    scores = cross_val_score(pipe, X, y, scoring=&#39;accuracy&#39;, cv=cv, n_jobs=-1,error_score=&quot;raise&quot;)  #array    # store results    results.append(scores)        # print    print(&#39;&gt;%s %.3f (%.3f)&#39; % (s, np.mean(scores), np.std(scores)))     ",
        "url": "/posts/LOF-outlier-pipeline.html"
      }
      ,
    
      "posts-polinomial-iterpolation-html": {
        "title": "Polynomial Interpolation",
        "author": "alesteba",
        "category": "",
        "content": "2023-03-04-polinomial-iterpolation                    Since many of the things that we do in the blog are about splines, in this post we're going to cover how to fit polynomials and splines to random scatter points.We'll use some of the basic scikit-learn functionality to avoid implementing the polynomial transformations from scratch. In this case a 2d aproach is more than enough, matplotlib is the selected plotting library.In&nbsp;[2]:     import numpy as npimport pandas as pdimport matplotlib.pyplot as plt     In&nbsp;[3]:     x = np.arange(0, 30)y = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70, 75, 88, 81, 87, 95, 100, 108, 135, 151, 160, 169, 179]plt.figure(figsize=(10,6))plt.scatter(x, y)plt.show()             In&nbsp;[4]:     from sklearn.preprocessing import PolynomialFeaturespoly = PolynomialFeatures(degree=2, include_bias=False)poly             Out[4]:PolynomialFeatures(include_bias=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PolynomialFeaturesPolynomialFeatures(include_bias=False)In&nbsp;[5]:     poly_features = poly.fit_transform(x.reshape(-1, 1))     In&nbsp;[6]:     from sklearn.linear_model import LinearRegressionpoly_reg_model = LinearRegression()poly_reg_model.fit(poly_features, y)             Out[6]:LinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()Polynomial features and Linear Regression work together to create the model that fits the points. This way of drawing a curve is a differnt aproach that the one that has been used in graphics development, for the moment we are playing around, and plotting the result.In&nbsp;[7]:     y_predicted = poly_reg_model.predict(poly_features)y_predicted             Out[7]:array([  1.70806452,   3.04187987,   4.70292388,   6.69119657,         9.00669792,  11.64942794,  14.61938662,  17.91657397,        21.54098999,  25.49263467,  29.77150802,  34.37761004,        39.31094073,  44.57150008,  50.1592881 ,  56.07430478,        62.31655014,  68.88602415,  75.78272684,  83.00665819,        90.55781821,  98.4362069 , 106.64182425, 115.17467027,       124.03474495, 133.22204831, 142.73658033, 152.57834101,       162.74733037, 173.24354839])In&nbsp;[8]:     plt.scatter(x,y)plt.plot(x, y_predicted,c=&#39;red&#39;)plt.show()             SPLINE ITERPOLATION&#182;The following cells contains the linear interpolation models for both regular polynomial and spline transformations. Then visualize the model fit to the points with a varying range of degrees.The higher the degree, both the polynomial and spline, the more accurate the model to the points. In a data science approach a lower degree may be better to avoid overfitting, but if we want to use the model for drawing and graphics purpose, a high degree that fits to the points is a great choice. Enjoy the samples below.In&nbsp;[13]:     lw = 2fig, ax = plt.subplots()ax.set_prop_cycle(    color=[&quot;black&quot;, &quot;teal&quot;, &quot;yellowgreen&quot;, &quot;gold&quot;, &quot;darkorange&quot;, &quot;tomato&quot;])# plot training pointsax.scatter(x, y)# fit polinomials:# reshape de x:x = x.reshape(-1, 1)# polynomial featuresfrom sklearn.linear_model import Ridgefrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import PolynomialFeatures# try different degrees to fit polynomials.for degree in [1,2,3, 10]:    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1e-3))    model.fit(x, y)    y_plot = model.predict(x)    ax.plot(x, y_plot, label=f&quot;degree {degree}&quot;)             c:\\Users\\Alberto-PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39773e-33): result may not be accurate.  return linalg.solve(A, Xy, assume_a=&#34;pos&#34;, overwrite_a=True).T        In&nbsp;[14]:     # vs spline fitting to data:# B-spline with 4 + 3 - 1 = 6 basis functionsfrom sklearn.preprocessing import SplineTransformer# fit polynomial:lw = 2fig, ax = plt.subplots()ax.set_prop_cycle(    color=[&quot;black&quot;, &quot;teal&quot;, &quot;yellowgreen&quot;, &quot;gold&quot;, &quot;darkorange&quot;, &quot;tomato&quot;])# plot training pointsax.scatter(x, y)# one more gradex = x.reshape(-1, 1)for degree in [2,5,10]:    # why ridge model¿?    model = make_pipeline(        # spline transfomer cool        SplineTransformer(n_knots=degree, degree=3),         Ridge(alpha=1e-3)    )    model.fit(x, y)    y_plot = model.predict(x)    ax.plot(x, y_plot, label=&quot;B-spline&quot;)    # ax.legend(loc=&quot;lower center&quot;)plt.show()             ",
        "url": "/posts/polinomial-iterpolation.html"
      }
      ,
    
      "posts-django-jupyter-notebook-html": {
        "title": "Django + Jupyter Notebooks",
        "author": "alesteba",
        "category": "",
        "content": "In this post we explore how to combine the django framework with jupyter notebooks.Sometimes this way of executing code from within the app can be very usuful to test our models.The following code must be executed in the first cell of each notebook.# Without this, you won't be able to import django modulesimport sys, os, django# Find the project base directoryBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))# Add the project base directory to the sys.pathsys.path.insert(0, BASE_DIR)# The DJANGO_SETTINGS_MODULE has to be set to allow us to access django importsos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"motor_perf.settings\")#  Allow queryset filtering asynchronously when running in a Jupyter notebookos.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"# This is for setting up djangodjango.setup()The Django models is accesible once the environment variable has been set.from django.contrib.auth.models import Userprint(User.objects.all())",
        "url": "/posts/django-jupyter-notebook.html"
      }
      ,
    
      "posts-clustering-html": {
        "title": "Clustering &amp; Dendograms Scikit-learn Python",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-25-clustering                    Agglomerative Clustering recursively merges pair of clusters of sample data; uses linkage distance. In this example we use the iris dataset to see how the algorithm performs with different parameters. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion. The affinity is the metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. If linkage is “ward”, only “euclidean” is accepted. If “precomputed”, a distance matrix (instead of a similarity matrix) is needed as input for the fit method.In&nbsp;[1]:     import numpy as npimport pandas as pd     In&nbsp;[2]:     from matplotlib import pyplot as pltfrom scipy.cluster.hierarchy import dendrogramfrom sklearn.datasets import load_irisfrom sklearn.cluster import AgglomerativeClustering     Load the iris dataset to test the algorithm and then visualize the generated clusters. We previosly know that three is the best number of clusters for the datset, the algorithm and the dendograms should be able to show that result. Changing the distance and the linkage parameters modifies the result, lets visualize it throw the following process.In&nbsp;[3]:     iris_data = load_iris()df = pd.DataFrame(    data=iris_data.data,     columns=iris_data.feature_names)     In&nbsp;[4]:     def plot_dendrogram(model, **kwargs):    # Create linkage matrix and then plot the dendrogram    # create the counts of samples under each node    counts = np.zeros(model.children_.shape[0])    n_samples = len(model.labels_)    for i, merge in enumerate(model.children_):        current_count = 0        for child_idx in merge:            if child_idx &lt; n_samples:                current_count += 1  # leaf node            else:                current_count += counts[child_idx - n_samples]        counts[i] = current_count    linkage_matrix = np.column_stack(        [model.children_, model.distances_, counts]    ).astype(float)    # Plot the corresponding dendrogram    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram    dendrogram(linkage_matrix, **kwargs)     The following code uses the distances and the linkage to plot dendograms asociated to each generated group of clusters.‘ward’ minimizes the variance of the clusters being merged.‘average’ uses the average of the distances of each observation of the two sets.‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.‘single’ uses the minimum of the distances between all observations of the two sets.In&nbsp;[5]:     # parameters to testlinkage = [ 'ward', 'complete', 'average', 'single' ]distances = [ 'euclidean', 'manhattan' , 'cosine' ]fig, axs = plt.subplots(4, 3, figsize=(15, 15))for l in range(len(linkage)):    for d in range(len(distances)):         # ward cant work manhattan and cosine distances        if linkage[l] == 'ward':            if (distances[d] == 'manhattan' or                 distances[d] == 'cosine'):                break        model = AgglomerativeClustering(            distance_threshold=0,             n_clusters=None,             linkage=linkage[l],             affinity=distances[d])        # fit the data        model = model.fit(df)        # print the data:                plot_dendrogram(model, truncate_mode=\"level\", p=3, ax = axs[l][d])             ",
        "url": "/posts/clustering.html"
      }
      ,
    
      "posts-k-means-pll-html": {
        "title": "K-Means Parallel Python Implementation",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-13-k-means-pll                    This post explores the possibilities of a simple k-means implementation. The algorithm uses the center_asignment function with a parallel approach. Take a look at the github links below to see the code and then explore the call graphs for both serial and parallel executions. Python multiprocessing creates an important overload making this implementation useful in big datasets running on propper parallelizable hardware, otherwise the result are worse.GITHUB DIRECT CODE EXEC&#182;To simplify things, direct evaluation of the code from github, check the following links to understand the full algorithm.In&nbsp;[12]:     import urllib.request     In&nbsp;[13]:     # https://github.com/waloncab/k-means-pll/blob/main/k_means_pll.pycode_alg = 'https://raw.githubusercontent.com/waloncab/k-means-pll/main/k_means_pll.py'response = urllib.request.urlopen(code_alg)data = response.read()exec(data)     In&nbsp;[14]:     # https://github.com/waloncab/k-means-pll/blob/main/k_means_wrap.py code_wrap = 'https://raw.githubusercontent.com/waloncab/k-means-pll/main/k_means_wrap.py'response = urllib.request.urlopen(code_wrap)data = response.read()exec(data)     PARALLEL CODE&#182;Lets see the headers of the methods involved in the algorithm execution:In&nbsp;[15]:     def init_centroids_random(datos, k):    \"\"\" init centroids random the first time and then choose based on best inertia\"\"\"    passdef init_centroids_best_inertia(datos, k, rand_iters, dist_func):    \"\"\" centroid coordinates based on the clusters points (mean of those points)\"\"\"    passdef centroid_coords(cluster):    \"\"\"calculate new centroids based on cluster data\"\"\"    passdef centroids_recalculate(clusters):    \"\"\" distance of concrete data point to each of the centroids \"\"\"    passdef centroid_points_dist(point, centroides, dist_func):    \"\"\" returns the list of clustered data to corresponding centroid based on distance \"\"\"    passdef centroid_asignment(datos, centroides, dist_func):    \"\"\" returns the list of clustered data to corresponding centroid based on distance \"\"\"    passdef centroid_asignment_parallel(datos, splits, centroides, dist_func):    \"\"\"parallel implementation of the centroid_asignment function\"\"\"    passdef point_labels_to_clusters(datos, label_mask, k):    \"\"\" returns the k clusters with their correspondent data points \"\"\"    pass     In&nbsp;[16]:     def loop_until_equal_centroids(        datos, clusters, centroides,     max_iters, abs_tol, rel_tol,     dist_func, splits):    \"\"\" loop behaviour, stop based on max_iters, or based on inertia \"\"\"    pass     The following code uses python multiprocessing library to split the data and execute the centroid_asginment function in different threads.In&nbsp;[17]:     def centroid_asignment_parallel(datos, splits, centroides, dist_func):    splitted = np.array_split(datos, splits)    pool = multiprocessing.Pool(splits)    params = []    for x in range(splits):        params.append([splitted[x], centroides, dist_func])    result = pool.starmap(centroid_asignment, params)    pool.close(); pool.join()    res_masks = [res[0] for res in result]    res_inert = [res[1] for res in result]     loss = sum(res_inert) / splits     label_mask = np.array(res_masks).reshape(-1)    return label_mask, loss     IRIS DATASET BASIC TEST&#182;Lets run a basic exemple and classify the data from the iris dataset.In&nbsp;[18]:     import numpy as npimport pandas as pdimport matplotlib.pyplot as plt     In&nbsp;[19]:     from sklearn.datasets import load_irisiris_data = load_iris()df = pd.DataFrame(    data=iris_data.data,     columns=iris_data.feature_names)df             Out[19]:                  sepal length (cm)      sepal width (cm)      petal length (cm)      petal width (cm)                  0      5.1      3.5      1.4      0.2              1      4.9      3.0      1.4      0.2              2      4.7      3.2      1.3      0.2              3      4.6      3.1      1.5      0.2              4      5.0      3.6      1.4      0.2              ...      ...      ...      ...      ...              145      6.7      3.0      5.2      2.3              146      6.3      2.5      5.0      1.9              147      6.5      3.0      5.2      2.0              148      6.2      3.4      5.4      2.3              149      5.9      3.0      5.1      1.8      150 rows × 4 columnsIn&nbsp;[20]:     data_array = np.array(iris_data['data'])     PYCALLGRAPH ALGORITHM VISUALIZATION&#182;In&nbsp;[21]:     # use pycall_graph to plot the call processingfrom pycallgraph import PyCallGraphfrom pycallgraph.output import GraphvizOutputfrom image_notebook import *from IPython.display import Image     In&nbsp;[22]:     graphviz_1 = GraphvizOutput()graphviz_1.output_file = 'pycallgraph_1.png'with PyCallGraph(output=graphviz_1):    kmeans = KMeans_UR(                k=3,        max_iters=500,    )    kmeans.fit(data_array)     In&nbsp;[23]:     html = export_image_html_notebook('./pycallgraph_1.png')IPython.display.HTML(html)             Out[23]:In&nbsp;[24]:     graphviz_2 = GraphvizOutput()graphviz_2.output_file = 'pycallgraph_2.png'with PyCallGraph(output=graphviz_2):    # using the multiprocessing algorithm        kmeans = KMeans_UR(                k=3,        max_iters=500,        splits=2,    )    kmeans.fit(data_array)    # use the second example for taking data:    labels = kmeans.cluster_tags()    cent = (kmeans.centroids())     Run the same algorithm in parallel with two data splits to understand the call overload produced by Python.In&nbsp;[25]:     html = export_image_html_notebook('./pycallgraph_2.png')IPython.display.HTML(html)             Out[25]:We observe that when multiprocessing behaviour is introduced Pyhton creates multiple calls to run different threads. Under a basic laptop or a small dataset the call overload is going to make the algorithm slower. There are some cases where this can get the expected speed-up.larger datasets, the iris dataset is not large enough to increse performace with multiprocessing.specific hardware for working with multiple threads, such as:dedicated GPU (may requiere changes in code to use it)highly parallelizable CPU, like Intel Xeon processor family.PLOT CLUSTERS AND CENTROIDS&#182;Plot the clusters and centroids to visualize the data, if the groups are well defined is because the algorithm is working as expected.In&nbsp;[26]:     from mpl_toolkits import mplot3d# Plot the clustered datafig = plt.figure(figsize = (15, 15))ax = plt.axes(projection =\"3d\") # Creating plotfor i in range(len(kmeans.clusters())):    # metodo para labeling the data:    ax.scatter3D (data_array[:, 0], data_array[:, 1], data_array[:,2], c= labels)ax.scatter(cent[:, 0], cent[:,1], cent[:,2],  marker='*', s=300,  c='r', label='centroid')             Out[26]:&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f5176f0f940&gt;        ",
        "url": "/posts/k-means-pll.html"
      }
      ,
    
      "posts-recursive-graph-neighbours-html": {
        "title": "Recursive Graph Neighbours",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-12-graph-depth                    In&nbsp;[1]:     import networkx as nximport matplotlib.pyplot as plt     In&nbsp;[2]:     G = nx.gnp_random_graph(100, 0.075, seed=None, directed=False)     In&nbsp;[3]:     nx.draw(G)             In&nbsp;[4]:     def neigh(G, node, depth):    node_list = []    if depth==0:        node_list.append(node)    else:        for neighbor in G.neighbors(node):            node_list.append(node)            node_list += neigh(G, neighbor, depth-1)    return list(set(node_list))     In&nbsp;[5]:     # For 10 random nodes, draw their correspondent subgraph with detph 1:import random# crate the figure and axesfig, axes = plt.subplots(2, 5, figsize=(24, 10))# unpack all the axes subplotsaxe = axes.ravel()# matplot with 5X10for i in range(10):    r_node = random.sample(list(G.nodes), 1)    neighbours = neigh(G, node=r_node[0], depth=1)    H = G.subgraph(neighbours)        nx.draw(H,             with_labels=True,             node_size=10,             alpha=1,             linewidths=10,            pos=nx.spring_layout(H),            cmap=plt.get_cmap('jet'),            ax=axe[i])             ",
        "url": "/posts/recursive-graph-neighbours.html"
      }
      ,
    
      "posts-map-filter-reduce-recursive-html": {
        "title": "Recursive / Map - Filter - Reduce",
        "author": "waloncab",
        "category": "",
        "content": "2022-10-03-recursive-definitions                    In&nbsp;[&nbsp;]:     def map_rec(f,l):    if l == []:        return l    else:        h = map_rec(f,l[1:])        h.insert(0,f(l[0]))        return(h)     In&nbsp;[&nbsp;]:     def filter_rec(f, l):    if l == []:        return l    else:        h = filter_rec(f,l[1:])        if f(l[0]):            h.insert(0,l[0])        return(h)     In&nbsp;[&nbsp;]:     def reduce_rec(f, l, s):    if l == []:        return l    elif len(l) == 1:        return f(s, l[0])    else:        l = f(l[0], reduce_rec(f,l[1:],s))        return(l)     ",
        "url": "/posts/map-filter-reduce-recursive.html"
      }
      ,
    
      "posts-clousure-callback-html": {
        "title": "Clousures as Callbacks",
        "author": "alesteba",
        "category": "",
        "content": "2022-10-03-clousure-callback                    Clousere definition:In&nbsp;[&nbsp;]:     def func1():   var = \"Enclosed Function\"   def func2():       var = \"Nested Function\"       print(var)   return func2res = func1()res     Returning a function allows us to execute something previously defined when that process ends.Without actually defining a class, we can group the definition of a procedure and its associated callback function, all in the same block of code.In&nbsp;[1]:     import timedef process_function(p_var):    # some algorithm that takes time.    time.sleep(1)    # callback function to return    def callback(call_param):        print(p_var, str(call_param))    return callback     We use the prevoius code to create 3 diferent calls that take time to complete and then print the result of their coresponding callback functions.In&nbsp;[2]:     # define multiple processesproceses = []for x in range(3):    proceses.append(process_function(x))c1, c2, c3 = proceses# use the callbacksprint(c1('var_call'))print(c2('var_call'))print(c3('var_call'))             0 var_callNone1 var_callNone2 var_callNone",
        "url": "/posts/clousure-callback.html"
      }
      ,
    
      "posts-hide-cells-jupyter-notebook-source-html": {
        "title": "Hide Cells in Jupyter Notebook From Source",
        "author": "alesteba",
        "category": "",
        "content": "2022-11-12-hide_cells_jupyter                    In&nbsp;[6]:     import nbformat as nbffrom glob import globdef hide_cells_jupiter(file_path):    # Text to look for in adding tags    text_search_dict = {        \"# HIDDEN\": \"remove-cell\",  # Remove the whole cell        \"# NO CODE\": \"remove-input\",  # Remove only the input        \"# HIDE CODE\": \"hide-input\"  # Hide the input w/ a button to show    }    ntbk = nbf.read(file_path, nbf.NO_CONVERT)    for cell in ntbk.cells:        cell_tags = cell.get('metadata', {}).get('tags', [])        for key, val in text_search_dict.items():            if key in cell['source']:                if val not in cell_tags:                    cell_tags.append(val)        if len(cell_tags) &gt; 0:            cell['metadata']['tags'] = cell_tags    nbf.write(ntbk, file_path)     In&nbsp;[7]:     import nbformat as nbffrom nbconvert.exporters import HTMLExporterfrom nbconvert.preprocessors import TagRemovePreprocessorfrom traitlets.config import Configimport yamldef basic_config():    # Setup config    c = Config()    c.TagRemovePreprocessor.remove_cell_tags = (\"remove-cell\",)    c.TagRemovePreprocessor.remove_all_outputs_tags = ('remove-output',)    c.TagRemovePreprocessor.remove_input_tags = ('remove-input',)    c.TagRemovePreprocessor.enabled = True     # Configure and run out exporter    c.HTMLExporter.preprocessors = [\"nbconvert.preprocessors.TagRemovePreprocessor\"]    return cdef export_notebook(note_path, out_path, c = basic_config):    # Setup config    c = basic_config()    exporter = HTMLExporter(config=c)    exporter.register_preprocessor(TagRemovePreprocessor(config=c),True)    output = exporter.from_filename(note_path)    # tener mucho cuidado con la estructura del path en el que quiero imprimir.    filepath = out_path    # get YAML:    with open(filepath, \"r\") as f:        # Make a dict from the first YAML block        data = next(yaml.load_all(f, Loader=yaml.FullLoader))        print(data)    # 3 Delete output file content    file = open(filepath, 'w')    file.close()    with open(filepath, 'w', encoding='utf-8') as yaml_file:            yaml_file.write(\"---\" + \"\\n\")            yaml.dump(data, yaml_file)            yaml_file.write(\"---\" + \"\\n\")            yaml_file.write(output[0])     In&nbsp;[8]:     hide_cells_jupiter('./2022-11-12-hide_cells_jupyter.ipynb')     In&nbsp;[9]:     export_notebook('./2022-11-12-hide_cells_jupyter.ipynb', '/mnt/f/S-1.Studio/s.ln_blog/blog/_posts/2022-08-11-hide_cells_jupyter.html')             {&#39;author&#39;: &#39;waloncab&#39;, &#39;categories&#39;: &#39;jekyll&#39;, &#39;date&#39;: &#39;2022-07-29 01:00:00 +0100&#39;, &#39;excerpt_separator&#39;: &#39;&lt;!--more--&gt;&#39;, &#39;layout&#39;: &#39;post_v2&#39;, &#39;permalink&#39;: &#39;/posts/:title.html&#39;, &#39;title&#39;: &#39;Hide Cells in Jupyter Notebook From Source&#39;}",
        "url": "/posts/hide-cells-jupyter-notebook-source.html"
      }
      ,
    
      "posts-latex-markdow-jekyll-html": {
        "title": "LateX for markdown (.md) in Jekyll",
        "author": "alesteba",
        "category": "",
        "content": "This is for anyone looking for how to use lateX whitin markdown (.md) files for jekyll. Jekyll won’t process the latex code, it has to be done in the browser with javascript. Include the following script calling CDN in the layout that contains your blog-post:    &lt;script    src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"    type=\"text/javascript\"&gt;    &lt;/script&gt;\\[W =   \\left[ {\\begin{array}{cc}    0       &amp; -u_{z} &amp;  u_{y}\\\\     u_{z}  &amp; 0      &amp; -u_{z}\\\\    -u_{y}  &amp;  u_{x} &amp;  0  \\end{array} } \\right]\\]\\[I + \\sin(\\theta) \\times W + 2*\\sin^2(\\frac{\\theta}{2})\\]",
        "url": "/posts/latex-markdow-jekyll.html"
      }
      ,
    
      "posts-networkx-graph-traversal-html": {
        "title": "NetworkX Graph Random Walk",
        "author": "alesteba",
        "category": "",
        "content": "graph_traverse                    NetworkX is powerfull python library for working with big graph structures. Let's analyze how to randomly walk directed graphs.In&nbsp;[52]:     import pylab as pimport networkx as nximport numpy as npimport random     In&nbsp;[53]:     G = nx.DiGraph()G.add_edge(\"A\",\"B\")G.add_edge(\"A\",\"H\")G.add_edge(\"H\",\"C\")G.add_edge(\"B\",\"C\")G.add_edge(\"B\",\"D\")nx.draw(G)p.show()             Randomly traversing a graph is a simple task, for the moment let's cover walking for a non-weighted directed graph.give the current_node a start valuefor each step:do an action with the current nodecalculate a new random value to select the next nodeIn&nbsp;[54]:     # randomly traverse all the graph:current_node = 'A'while (True):    # identify current node neighbors    n_list = list(G.neighbors(current_node))    #TODO: whatever action with the current node    print(\"Current Node: \" + current_node)    # break if node doesn't have neighbors    if len(n_list) == 0:        break    # compute next node    rand_index = random.randrange(0, len(n_list))    current_node = n_list[rand_index]                Current Node: ACurrent Node: BCurrent Node: CLet's randomly generate a bigger directed graph and add weight to the edges. Notice that deciding the next node implies calculating a random value using the neighbors edge weights.In&nbsp;[55]:     G = nx.gnm_random_graph(100, 250, seed=None, directed=True)     In&nbsp;[56]:     for node in G.nodes():    neighbors = list(G.neighbors(node))    # random list of numbers to sum-up one    a = np.random.random(len(neighbors))    a /= a.sum()    for e in range(0, len(neighbors)):        cur_node = node        edg_node = neighbors[e]        edg_weig = a[e]        G[cur_node][edg_node]['weight'] = edg_weig     In&nbsp;[57]:     # basic printing, allows a rapid view of how the graph looks in space.nx.draw(G, with_labels = True)p.show()             In&nbsp;[58]:     nx.draw_shell(G, with_labels = True)p.show()             In&nbsp;[59]:     # Now, the previous algorithm needs to be modified to consider the weights in the nodes whenever the next node is going to be calculated.import random# randomly traverse all the graph:def random_walk(G):    current_node = 0    while (True):        # identify current node neighbors        n_list = list(G.neighbors(current_node))        #TODO: whatever action with the current node        print(\"Current Node: \" + str(current_node))        # break if node doesn't have neighbors        if len(n_list) == 0:            break        weights = []        for i in range(0, len(n_list)):            w = G[current_node][n_list[i]]['weight']            weights.append(w)        # random with weights:        # since only one choice is needed take the [0]: function returns a list        current_node = np.random.choice(n_list, 1, p=weights)[0]     In&nbsp;[60]:     random_walk(G)             Current Node: 0Current Node: 11Current Node: 7Current Node: 92Current Node: 88Current Node: 56Current Node: 83Current Node: 40Current Node: 59Current Node: 77Current Node: 76Current Node: 70Current Node: 61Current Node: 41Current Node: 42Current Node: 64Current Node: 85Current Node: 31Current Node: 94Current Node: 95Current Node: 66Current Node: 55Current Node: 62Current Node: 82Current Node: 99Current Node: 80Current Node: 10Current Node: 69Current Node: 2Current Node: 44Current Node: 50Current Node: 25Current Node: 31Current Node: 36Current Node: 71Current Node: 73Current Node: 68Current Node: 83Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 40Current Node: 59Current Node: 77Current Node: 76Current Node: 11Current Node: 63Current Node: 13Current Node: 71Current Node: 73Current Node: 68Current Node: 83Current Node: 89Current Node: 57This is the randomly traversed path, lets see what happens if executed a second time.In&nbsp;[61]:     random_walk(G)             Current Node: 0Current Node: 11Current Node: 7Current Node: 84Current Node: 97Current Node: 12Current Node: 89Current Node: 57In&nbsp;[62]:     # lets see if I can automate the working with notebooks for jelyll web development:# metadata cells can be edited.# https://thedatafrog.com/en/articles/jupyter-notebooks-web-pages/# https://jupyterbook.org/en/stable/content/metadata.html#jupyter-cell-tags     ",
        "url": "/posts/networkx-graph-traversal.html"
      }
      ,
    
      "posts-random-vector-within-cone-html": {
        "title": "Random Vector within Cone",
        "author": "alesteba",
        "category": "",
        "content": "Rendering engines use Quaterinions for complex rotations in 3D-space. Here, a different approach is going to be use to generate a random vector within a defined cone. Follow the next steps:  Generate a random unit vector.    coneDirection = (pl1- pl2) / np.linalg.norm(coneDirection)    randomVector = v / np.linalg.norm(v)  Project this vector onto the ‘plane’ with the cone’s direction vector as a normal.    projectedVector = randomVector - coneDirection*(np.dot(coneDirection,randomVector))This vector is now perpedicular to the cone's direction, and can be taken as an axis around which to rotate the cone.  Generate a random angle, theta, between 0 and the cone’s maximum angle.    theta = random.uniform(0, self.angle)  Set up a rotation matrix for theta degrees around the axis projectedVector. Rodrigues’ Rotation Formula gives an efficient method for computing the rotation matrix R in 3D-space corresponding to a rotation by an angle theta about a fixed axis specifiedby the unit vector u=(x,y,x) in R^3\\[W =   \\left[ {\\begin{array}{cc}    0       &amp; -u_{z} &amp;  u_{y}\\\\     u_{z}  &amp; 0      &amp; -u_{z}\\\\    -u_{y}  &amp;  u_{x} &amp;  0  \\end{array} } \\right]\\]\\[I + \\sin(\\theta) \\times W + 2*\\sin^2(\\frac{\\theta}{2})\\]The following code translates the math to numpy pyhton arrays.    # rotation matrix:    u_x= projectedVector[0]    u_y= projectedVector[1]    u_z= projectedVector[2]    w = np.array( [        [0, -u_z, u_y],        [u_z, 0, -u_x],        [-u_y ,u_x, 0],    ]).astype(float)    rot_m = np.identity(3) + (math.sin)*w + (2*sin(theta/2) **2)) * np.linalg.matrix_power(w, 2)Rotate the cone’s direction using that matrix.    res_vec = rot_m @ np.array(coneDirection).T",
        "url": "/posts/random-vector-within-cone.html"
      }
      ,
    
      "demos-opengl-transformations-html": {
        "title": "Spline Transformations - Rendering OpenGL",
        "author": "alesteba",
        "category": "",
        "content": "Rendering a spline shape with a dedicated graphics engine written in Python.The scene graph architecture allows to create a custom spline-shape geometry and then locally transform the entire object with the disered operations.All matrix and vector operations are abstracted by the framework, allowing to translate, rotate and scale from well-defined methods.The stored model matrices are prepared to work with global and local transformations. Read the following post to deeply understand how matrix transformations works:Matrix Transformations for Rendering 3D Objects",
        "url": "/demos/openGL-transformations.html"
      }
      ,
    
      "posts-rendering-engine-architecture-html": {
        "title": "Rendering Engine Architecture",
        "author": "alesteba",
        "category": "",
        "content": "      Graphics Library vs Rendering Engine    OpenGL is a graphics library with many functions for drawing complex geometries based on more simple geometry primitives such as points, lines and triangles.   A rendering engine is a well defined framework that uses some of the graphics library functions to deliver a simple way to construct 3d scenes.   In order to understand the rendering engine architecture, lets have a grasp of what a graphics pipeline looks like.        Graphics Pipeline    The graphics pipeline is the process of turning a 3D model into what the computer displays in the 2D screen.  The pipeline has the following stages:                  application: is executed by the software on the main processor, the CPU, initializing the window where graphics will be displayed during the following steps.                    geometry: determining the position of each vertex of the geometric shapes that need to be rendered, implemented by a program called a vertex shader.                    rasterization: establish the relationship between screen pixels and geometric shapes. It is responsible for the majority of the operations with polygons and their vertices        It can be divided in the following steps:                  [start] in: object coordinates          Model &amp; Camera transformations:          Lighting          Projection          Clipping          Window - view port transformation          [end] out: device (screen) coordinates                            pixel processing: associates each pixel in the render image with a color, involves a program called fragment shader.                  Scene Tree    Prior to any of the rendering steps mentioned before, the rendering engine has to work with some abstract representation of a 3D-scene.  This scene is sometimes structured as a tree since it’s simple to calculate complex transformations applied to object hierarchies.    Within this hierarchy each of the 3D objects must store the following data:          matrix for its local transformation      lis of references to child objects      reference to a parent object        Notice that within the same class, a full tree structure has beend defined. Some of the functions this ‘gameObject’ class needs to have are:          add / remove to manage child / parent objects      worldMatrix to calculate the global position      getChildren to convert the scene tree to a list        With this simple ingridients the tree structure the 3D scene can easily be rendered mantaining each object position relative to parent / child.  Keep in mind that the model matrix (matrix for local transformation) can accumulate the result of many transformations,   this transformations apply to the hierarchy of parent and children.        Model Matrix    It stores the current location, orientation and scale of a ‘gameObject’. The aculmulated transformations end up stored within the matrix data.  Why is so important? The global positions of any of the mesh vertices that may actually be rendered won’t be stored,  they are calculated based on the object model matrix every frame when they need to be rendered on screen.  Have a look at the diferent matrices operations that can take within the object local / global transformations:  Matrix Transformations for Rendering 3D Objects    When transforming a set of points with a matrix:          points are multiplied by the matrix in the vertex shader      new coordinates are passed along to the fragment shader      new coordinates of the points are not permantently stored      ",
        "url": "/posts/rendering_engine_architecture.html"
      }
      ,
    
      "posts-matrix-transformations-html": {
        "title": "Matrix Transformation for Rendering 3D objects",
        "author": "alesteba",
        "category": "",
        "content": "    Transformations are at the core of any rendering engine.     Vectors and matrices are the basic data structures that allow to    design and create functions to transform set of points in certain geometric way. Points / Vectors / Matrices    Both points and vectors are represented by a list of numbers, but they have different geometric interpretations.    Points are simple a defined position in a space but vectors represent a direction within that space.    Matrices are the best mathematical construct to apply transformations to the points and vectors, GPUs are highly optimized    to compute matrix multiplications in parallel. What kind of operations are needed in the 3D space ? Well, in any rendering engine, we require the following:    translation    rotation    scale Keep reding the text and imagine that transformations are applied from the origin of the coordinate system (global coordinates),     we'll consider local transformations later  4x4 Matrix in a 3D Space Homogeneous coordinates are a system of coordinates used in projective geometry.    They have the advantage that the coordinates of points, including points at infinity, can be represented using finite coordinates.    Since translation is not a linear transformation we need to embed 3x3 matrices in a 4x4 matrices, find out why Basic Transformation MatricesFor any given object we need to translate, rotate, and scale. Each one of this scene objects need to store transformation data in a 4x4 matrix. The matrix multiplication allow to easily modify the transformation data the object stores.The following blocks of code create the most basic matrices in numpy arrays.Model Matrix        A matrix is used to store the transformation of any object, but what about the points / vertices of that object in the case that     it renders some kind of mesh ?        Storing the transformation in the model matrix allows :             chain transformations by multiplying the model matrix of the object, the result matrix will store the accumulated transformations.        render a complex mesh without having to store the vertices of the mesh inside the object.    def init_Identity():    return np.array( [        [1, 0, 0, 0],        [0, 1, 0, 0],        [0 ,0, 1, 0],        [0, 0, 0, 1]    ]).astype(float)def init_Translation(x,y,z):    return np.array( [        [1, 0, 0, x],        [0, 1, 0, y],        [0 ,0, 1, z],        [0, 0, 0, 1]    ]).astype(float)    The followings lines of code represent the rotation matrices for the x,y,z axes.    Rotation happens around an axis, and the rotation matrix does not move the axis.    Rotation can be produced around any vector, but we are considering just the rotation around the     basis vectors (axis) since other rotations can be derived later from the world matrix.def init_RotationX(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [1, 0,  0, 0],        [0, c, -s, 0],        [0 ,s,  c, 0],        [0, 0,  0, 1]    ]).astype(float)def init_RotationY(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [ c, 0, s, 0],        [ 0, 1, 0, 0],        [-s ,0, c, 0],        [ 0, 0, 0, 1]    ]).astype(float)def init_RotationZ(angle):    c = cos(angle)    s = sin(angle)    return np.array( [        [c, -s, 0, 0],        [s, c, 0, 0],        [0 ,0, 1, 0],        [0, 0, 0, 1]    ]).astype(float)    This scale matrix only accepts one parameter scaling the object uniformly along the x,y, axes.def init_Scale(s):    return np.array( [        [s, 0, 0, 0],        [0, s, 0, 0],        [0 ,0, s, 0],        [0, 0, 0, 1]    ]).astype(float) Local vs Global Coordinates     When we multiply any of the previous matrices by some point we are transforming that point in a global coordinate system (Origin(0,0,0)).     For example, when multiplying a point by the translation matrix the point moves along the basis x,y,z axis.    Local transformations require to define an internal local coordinate system. Origin, orientation, and scale of the    local coordinate axes are chosen for convenience, but usually the center of the object is selected to transform locally. How to use matrix multiplication to perform transformations in Local Coordinate Systems             Let's keep it simple, in order to perform any global transformation we chain matrix multiplications on the left side of expression.        To achieve local transformations just multiply on the right side of the expression.         Keep in mind that matrix multiplication is not commutative: A*B != B*A                 Global Transformation: T3 * T2 * T1 * M(model_matrix)        Local Transformation: M(model_matrix) * T1 * T2 * T3     Perspective Matrix     Perspective matrix for rendering the scene.    Frustum: truncated pyramid that defines the visible region.    Parameters            near / far distance:         angle of view: the angle between from and bottom frustum planes.        aspect ratio: width / height of the rendered image.    def init_Perspective(angleOfView=60, aspectRatio=1, near=0.1, far=1000):    #convert to radians    a = angleOfView *pi/180    d = 1.0 / tan(a/2)    r = aspectRatio    b = (far + near) / (near - far)    c =  2 * far * near / (near - far)    return np.array( [        [d/r, 0, 0, 0],        [0, d, 0, 0],        [0 ,0, b, c],        [0, 0, -1, 0]    ]).astype(float)    Within the spline context, all this properties allow simple and more complex transformations to take place.    Some bezier operations are faster in a matrix form, and whenever a global/local transformation is needed there are matrix multiplications underneath.    Check some of the demos to feel the movement.",
        "url": "/posts/matrix_transformations.html"
      }
      ,
    
      "posts-git-automation-html": {
        "title": "Git Commit Automation with Python",
        "author": "alesteba",
        "category": "",
        "content": "This web page is a small complex piece of software. There are a few layers that composes the web, having jekyll as the backend and standard html, css, and javascript on the front-end. Since jekyll is a lightweight static web page generator, the site has to be built before uploading it to any remote server. This is a very repetitive process that could be automated. In this blog post we are going to see a simple bash script to use git version control and upload the built web-page to github-pages.Steps executed by the script:  use [ jekyll bundle build ] to build the web page into the _site folder.  copy the _site folder to some other folder and start a git repository in there.  automate the git commit with the following lines of code.The following lines specify the basic operations that can be done with your repository. Here, a random word function is being used to generate the commit identification message.The script is hardcoded for whis web-site folder structure, in case of using it modify it to fit your folders.#!/bin/bash# copy the files to the destination foldercp -r ./_site/* ../s.ln_blog_prod;# Save where you are and cd to other dirpushd ../s.ln_blog_prod;pwd;git add .;# list remotegit remote -v;# random txt &amp; numrandomTxt=$(cat /dev/urandom | tr -dc '[:alpha:]' | fold -w ${1:-4} | head -n 1);randomNum=$(cat /dev/urandom | tr -dc '[:digit:]' | fold -w ${1:-4} | head -n 1);echo $randomTxt;echo $randomNum;# create the commitgit commit -m \"$randomTxt$randomNum\";# has to be executed with sudosudo git remote set-url origin git@github.com:waloncab/s.ln_blog;# push to githubgit push -f --set-upstream origin master;# get back where you were at the beginning.popd;",
        "url": "/posts/git_automation.html"
      }
      ,
    
      "posts-plotly-web-export-html-html": {
        "title": "Plotting Splines with Plotly and export into HTML",
        "author": "alesteba",
        "category": "",
        "content": "                                                                                                                This plot has been generated using Plotly. There are many scenarios where a completly graphics engine is not necesary. Static visualization can be accomplished with simple libraries such as this one. Visualizing data is such a required task these days, many applications need it. Here it's done just for fun and to enjoy the delghtfull spline curves. Let's cover the basics of pltly and how to export the generated plots to ann html format so it can be integrated to any web-platform.                Keep in mind what your target platforms for the plots are, and then have a look what fits your project best. In this case plotly instead of matplotlib or seaborn, allow simple html export with the full plotting toolbar. This small features make a difference when it comes to the export, have a look at the  documentation        First, make sure you have installed Plotly in your pyhton enviroment,            pip install plotly                Now we are going to plot the data. Transform it into X and Y components, then use the Plotly commands to setup the axis and show it.        This code has been copied from Jupyter notebook cell, use this notebooks to keep code and plotting data organized before auploading to remote servers.            import plotly.express as px        fig = px.line(        x = np.squeeze(np.asarray(X)),         y = np.squeeze(np.asarray(Y))        )    # scale the axis properly    fig.update_yaxes(        scaleanchor = \"x\",        scaleratio = 1,    )        fig.show()                After plotting the data, we need to export the generated graph to an html format. The following snippet does so.        Notice the flags full_html=False, include_plotlyjs='cdn', they import the library with a CDN generating some lightweight script that can be eassily copied.            fig.write_html(\"./exported/random_0.html\",    full_html=False,    include_plotlyjs='cdn')        Creating Animations           Animations make plotting data more appealing, the following graph uses Plotly animations to move a point along the spline.        There is not much extra code required to create this animation, enjoy the plotting area and then have a look at the source.                                                                                                x = np.squeeze(np.asarray(X))y = np.squeeze(np.asarray(Y))N = 50# Create figurefig = go.Figure(        data=[go.Scatter(x=x, y=y,                     mode=\"lines\",                     line=dict(width=2, color=\"blue\")),          go.Scatter(x=x, y=y,                     mode=\"lines\",                     line=dict(width=2, color=\"blue\"))        ],    layout=go.Layout(        updatemenus=[dict(type=\"buttons\",                          buttons=[dict(label=\"Play\",                                        method=\"animate\",                                        args=[None])])]),                                       )fig.update_yaxes(    scaleanchor = \"x\",    scaleratio = 1,)We duplicate the scatter plot since we want to see the underlying spline when the animation is being played, it is just the way the frameweork works.Then establish the frames for the animations, by traversing N steps.fig.frames =    [go.Frame(        data=[go.Scatter(            # here the spline-framework is being used to generate the proper data            # use your x and y data to create the animation.            move_fwd(list_bezier, itr_step, 5.0),            x= np.asarray(itr_step.get_L().get_point(itr_step.get_T())[0]),            y= np.asarray(itr_step.get_L().get_point(itr_step.get_T())[1]),            mode=\"markers\",            marker=dict(color=\"red\", size=10))])        for k in range(N)]fig.show()",
        "url": "/posts/plotly-web-export-HTML.html"
      }
      ,
    
      "demos-audio-visualization-003-html": {
        "title": "Audio Visualization sp.002",
        "author": "alesteba",
        "category": "",
        "content": "Piano key strokes are more fun when you visualize in some form or another the sound produced.Closed spline shape rendered along this short track, notice the slow-fast waves the contour forms.",
        "url": "/demos/audio-visualization-003.html"
      }
      ,
    
      "demos-audio-visualization-002-html": {
        "title": "Audio Visualization sp.002",
        "author": "alesteba",
        "category": "",
        "content": "Everything you see in the video is generated at run-time. This time the audio visualizer uses not just a simple mesh but a line renderer to distinguish the contour of the shape.The drums make the shape generate aggressive but very pleasant curves.",
        "url": "/demos/audio-visualization-002.html"
      }
      ,
    
      "demos-audio-visualization-001-html": {
        "title": "Audio Visualization sp.001",
        "author": "alesteba",
        "category": "",
        "content": "How frequency bands can be used to make dynamic meshes. The shape is modified at real-time by a radial disposition of those bands.",
        "url": "/demos/audio-visualization-001.html"
      }
      ,
    
      "demos-breath-animation-html": {
        "title": "Reel Showcase",
        "author": "alesteba",
        "category": "",
        "content": "This time with breathing graphics, real time parallel processing for dynamic spline follow. Closed loop behavior algorithm allows to follow any closed line shape at a constant speed. A big challenge is keeping the iteration distance independent from the actual spline path that we’re iterating through.",
        "url": "/demos/breath-animation.html"
      }
      ,
    
      "demos-organic-algorithms-html": {
        "title": "Organic Algorithms",
        "author": "alesteba",
        "category": "",
        "content": "This video is about how to add organic movement to the points conforming the line shape.Kinematic alogorithms use different interpolation methods to transport the spline dots smoothly in space.When we combine the lerp effect with some random seed generation to determine where to move the desired dot, we achive some result similar to the one in the video.",
        "url": "/demos/organic-algorithms.html"
      }
      ,
    
      "demos-motion-graphics-html": {
        "title": "Motion Graphics",
        "author": "alesteba",
        "category": "",
        "content": "Scaling the project to handle different types of lines.Following path behavior within procedural line animations to make pleasant effects.",
        "url": "/demos/motion-graphics.html"
      }
      ,
    
      "demos-demo-reel-aaa-html": {
        "title": "Reel Showcase",
        "author": "alesteba",
        "category": "",
        "content": "Traversing splines in real time is computationally expensive.In order to handle all of this movement, a parallel approach has been introduced to certain algorithms.",
        "url": "/demos/demo_reel-AAA.html"
      }
      ,
    
      "posts-casteljau-s-algorithm-html": {
        "title": "Casteljau&apos;s Algorithm",
        "author": "alesteba",
        "category": "",
        "content": "Sometimes you need to define n-point curves, and generic bezier may fit your needs in those cases.The following lines of code represent how to design a generic bezier curve, n-grade curve.This algorithm uses recursion to iterate throw the entire interpolation points.Parameters:  points: the vector containing the curve modeling points.  t: the interpolation state [0 - 1]Notice the interpolation parameter t affects the entire curve and it does not dependon the number of points the curve is defined.public static Vector3 getPoint_R (List&lt;Vector3&gt; points, float t){  if (points.Count == 1)  { return points [0]; }  List&lt;Vector3&gt; recursive_call = new List&lt;Vector3&gt; ();  for (int i = 0; i &lt; (points.Count - 1); i++)  {    Vector3 newPoint = (1 - t) * points [i] + t * points [i + 1];    recursive_call.Add(newPoint);  }  return getPoint_R (recursive_call, t);}",
        "url": "/posts/Casteljau&apos;s-Algorithm.html"
      }
      ,
    
      "posts-bezier-curves-html": {
        "title": "Beizer Curves",
        "author": "alesteba",
        "category": "",
        "content": "In this post we understand how to get a point in a Bezier curve. These curves are about interpolation, the most used ones are cubic bezierssince they can be really good optimized. Given an interpolation parameter t, the coordinates of the respective points can be calculated with a concrete formula.Parameters:  t: the interpolation state [0 - 1]  w: weight values in the same dimensions, all x coordinate values, for example.This simple function returns the point coordinate for the interpolation value.However, notice the output and weights are floats, what means that we are constructing the curve for each coordinate independently, {X, Y, Z}public static float Bezier_3 (float t, float[] w){  if (w.Length != 4) {    throw new ArgumentException (\"List should have 4 points to be a cubic bezier\");  }  float t2 = t * t;  float t3 = t2 * t;  float mt = 1-t;  float mt2 = mt * mt;  float mt3 = mt2 * mt;  return w[0]*mt3 + 3*w[1]*mt2*t + 3* w[2]*mt*t2 + w[3]*t3;}Once the parameters are independent from the world-space, we can better optimize and generate concrete bezier functions for 2D or 3D space. Have a detail look on how the previous function is used to construct the curve for 3D space. Now, if the use case is a simple 2D space, we can remove the correspondent weights from the {Z} coordinate.Notice that a reasonable computation time is saved.public static Vector3 getPoint(List&lt;Vector3&gt; points, float t){  if (points.Count != 4) {    throw new ArgumentException (\"List should have 4 points to be a cubic bezier\");  }  float[] w_x = null; float[] w_y = null; float[] w_z = null;  decompose_weight (points, ref w_x, ref w_y, ref w_z);  float x = Bezier_3(t, w_x);  float y = Bezier_3(t, w_y);  float z = Bezier_3(t, w_z);  return new Vector3 (x, y, z);}The decompose weights instructions just reorganizes the List {X;Y;Z} components intoseparated lists containing the individual space coordinate for each one.",
        "url": "/posts/bezier-curves.html"
      }
      ,
    
      "posts-interpolation-spline-html": {
        "title": "Interpoaltion in Graphics",
        "author": "alesteba",
        "category": "",
        "content": "What traversing splines looks like?Interpolation in one of the core features of graphics development, you have it almost in every small tool that the game engine contains.Within the spline framework a linear interpolation is used to traverse shapes. Lets see some of the most relevant types of interpolation:  linear interpolation  polynomial interpolation  spline interpolation  Hermite interpolationDo not mistake the fact that within a spline a linear interpolation is used to go from the start to the end of the curve.In fact we use this linear approach for any iterable line / curve. A spline interpolation could be used to move an object alonga spline.Linear interpolation is the basic tool used in many cases. It interpolates at a constant pace from point a to point b.double interpolate_linear (double y1, double y2, double mu){   return(y1*(1-mu)+y2*mu);}Cubic interpolation is widely used when the movement needs some smooth look (polynomial interpolation).double interpolate_cubic(double y0, double y1, double y2, double y3, double mu){   double a0,a1,a2,a3,mu2;   mu2 = mu*mu;   a0 = y3 - y2 - y0 + y1;   a1 = y0 - y1 - a0;   a2 = y2 - y0;   a3 = y1;   return(a0*mu*mu2+a1*mu2+a2*mu+a3);}What other scenarios is interpolation used?  For any animation whether 2d or 3d, interpolation is used inside the skeleton model.  Inside camera movement interpolation allows smooth follow behavior.  Dynamic movement NPC’s constantly use interpolation to adapt the chasing movement.",
        "url": "/posts/interpolation-spline.html"
      }
      ,
    
      "demos-plain-textures-procedural-terrain-html": {
        "title": "Plain-Textures Procedural Terrain",
        "author": "alesteba",
        "category": "",
        "content": "Endless procedural generation in the context of hill racing games. Using procedural content algorithms for edge generation and then create biomes along those lines.",
        "url": "/demos/plain-textures-procedural-terrain.html"
      }
      ,
    
      "demos-endless-procedural-generation-html": {
        "title": "Endless Procedural Generation",
        "author": "alesteba",
        "category": "",
        "content": "Generative grammars for biome and shape generation. The grammar rules specify how slopes and shapes can be generated for each biome. Randomly walking a graph generates endless biomes along the car moves in the scene.",
        "url": "/demos/endless-procedural-generation.html"
      }
      
    

  };
</script>

<script src="https://sln-alesteba.github.io/portfolio/assets/js/lunr.min.js"></script>
<script src="https://sln-alesteba.github.io/portfolio/assets/js/search.js"></script>

<!-- https://learn.cloudcannon.com/jekyll/jekyll-search-using-lunr-js/ -->

            <br>

            <div class="footer">

    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/rotate.css">
    <link rel="stylesheet" href="https://sln-alesteba.github.io/portfolio/assets/css/footer.css">

    <div class="grid-container-footer">

        <div class="item1" id="rotator">
            <img src="https://sln-alesteba.github.io/portfolio/assets/img/fire_buble.png" alt="Walon Cab" width="128" height="128" align="center" class="rotate">
        </div>

        <div class="item2">
            <p class="right">Graphics rendering and spline algorithms. Kinematics from the bezier curves by  traversing generated paths, using some data science techniques and algorithms to enhance the process. Stay tunned for the Spline Lab!</p>

            <p align="center">
                &copy; 2023 alesteba
            </p>
        </div>

        <div class="item3">
            <p>
                Check out some of the resources out there! You'll find graphics, 
                splines, kinematics and code !
            </p>

            <p align="center">
                <a href="https://www.youtube.com/channel/UCJX8AUDFcQJMjY1zRivvZqw" class="fa fa-youtube"></a>
                <a href="https://www.instagram.com/sln-alesteba/" class="fa fa-instagram"></a>
                <a href="https://www.instagram.com/sln-alesteba/" class="fa fa-facebook"></a>
                <a href="https://twitter.com/WalonCab" class="fa fa-twitter"></a>
            </p>
        </div>  
    </div>
</div>

        </div>

    </body>

</html> 